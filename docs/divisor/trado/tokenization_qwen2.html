<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 16.0.0"/>
    <title>divisor.trado.tokenization_qwen2 API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:.75rem center;margin-bottom:1rem;}.pdoc .alert > em{display:none;}.pdoc .alert > *:last-child{margin-bottom:0;}.pdoc .alert.note{color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .alert.tip{color:#0a3622;background-color:#d1e7dd;border-color:#a3cfbb;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%230a3622%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%206a6%206%200%201%201%2010.174%204.31c-.203.196-.359.4-.453.619l-.762%201.769A.5.5%200%200%201%2010.5%2013a.5.5%200%200%201%200%201%20.5.5%200%200%201%200%201l-.224.447a1%201%200%200%201-.894.553H6.618a1%201%200%200%201-.894-.553L5.5%2015a.5.5%200%200%201%200-1%20.5.5%200%200%201%200-1%20.5.5%200%200%201-.46-.302l-.761-1.77a2%202%200%200%200-.453-.618A5.98%205.98%200%200%201%202%206m6-5a5%205%200%200%200-3.479%208.592c.263.254.514.564.676.941L5.83%2012h4.342l.632-1.467c.162-.377.413-.687.676-.941A5%205%200%200%200%208%201%22/%3E%3C/svg%3E");}.pdoc .alert.important{color:#055160;background-color:#cff4fc;border-color:#9eeaf9;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23055160%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%200a2%202%200%200%200-2%202v12a2%202%200%200%200%202%202h12a2%202%200%200%200%202-2V2a2%202%200%200%200-2-2zm6%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .alert.caution{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M11.46.146A.5.5%200%200%200%2011.107%200H4.893a.5.5%200%200%200-.353.146L.146%204.54A.5.5%200%200%200%200%204.893v6.214a.5.5%200%200%200%20.146.353l4.394%204.394a.5.5%200%200%200%20.353.146h6.214a.5.5%200%200%200%20.353-.146l4.394-4.394a.5.5%200%200%200%20.146-.353V4.893a.5.5%200%200%200-.146-.353zM8%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .decorator-deprecated{color:#842029;}.pdoc .decorator-deprecated ~ span{filter:grayscale(1) opacity(0.8);}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:27px;vertical-align:bottom;width:50px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../trado.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;divisor.trado</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="class" href="#Qwen2Tokenizer">Qwen2Tokenizer</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#Qwen2Tokenizer.__init__">Qwen2Tokenizer</a>
                        </li>
                        <li>
                                <a class="variable" href="#Qwen2Tokenizer.vocab_files_names">vocab_files_names</a>
                        </li>
                        <li>
                                <a class="variable" href="#Qwen2Tokenizer.model_input_names">model_input_names</a>
                        </li>
                        <li>
                                <a class="variable" href="#Qwen2Tokenizer.decoder">decoder</a>
                        </li>
                        <li>
                                <a class="variable" href="#Qwen2Tokenizer.errors">errors</a>
                        </li>
                        <li>
                                <a class="variable" href="#Qwen2Tokenizer.byte_encoder">byte_encoder</a>
                        </li>
                        <li>
                                <a class="variable" href="#Qwen2Tokenizer.byte_decoder">byte_decoder</a>
                        </li>
                        <li>
                                <a class="variable" href="#Qwen2Tokenizer.bpe_ranks">bpe_ranks</a>
                        </li>
                        <li>
                                <a class="variable" href="#Qwen2Tokenizer.cache">cache</a>
                        </li>
                        <li>
                                <a class="variable" href="#Qwen2Tokenizer.pat">pat</a>
                        </li>
                        <li>
                                <a class="variable" href="#Qwen2Tokenizer.vocab_size">vocab_size</a>
                        </li>
                        <li>
                                <a class="function" href="#Qwen2Tokenizer.get_vocab">get_vocab</a>
                        </li>
                        <li>
                                <a class="function" href="#Qwen2Tokenizer.bpe">bpe</a>
                        </li>
                        <li>
                                <a class="function" href="#Qwen2Tokenizer.convert_tokens_to_string">convert_tokens_to_string</a>
                        </li>
                        <li>
                                <a class="function" href="#Qwen2Tokenizer.decode">decode</a>
                        </li>
                        <li>
                                <a class="function" href="#Qwen2Tokenizer.save_vocabulary">save_vocabulary</a>
                        </li>
                        <li>
                                <a class="function" href="#Qwen2Tokenizer.prepare_for_tokenization">prepare_for_tokenization</a>
                        </li>
                </ul>

            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22160%22%20viewBox%3D%220%200%20150%2080%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M132.316%2048.886c.276-4.679%202.342-6.698%204.409-7.982s4.27-1.165%206.751-1.055c1.586.07%203.044.156%204.222-.482%201.142-.619%202.026-1.932%202.162-3.739.268-3.576-1.929-5.368-5.006-5.551s-7.599.524-10.517%201.606c-4.455%201.652-8.588%206.606-9.552%208.992s-2.342%206.193-1.745%2010.873%202.664%209.221%205.878%2011.79%205.878%203.808%2010.103%204.312%203.444.229%206.062.229%205.006-2.202%204.914-4.909-2.296-5.001-4.501-4.863-3.077.505-5.281.229-7.715-2.064-7.899-9.451z%22%20fill%3D%22%23198754%22/%3E%3Ccircle%20cx%3D%22101.504%22%20cy%3D%2248.943%22%20r%3D%2214.208%22%20fill%3D%22none%22%20stroke%3D%22%23198754%22%20stroke-width%3D%229.354%22/%3E%3Cpath%20d%3D%22M87.81.002c-3.637.065-5.001.454-7.014%201.232s-3.443%201.363-6.3%204.282c-1.723%201.76-3.148%205.019-3.776%207.329-.413%201.521-.316%202.63-.316%202.63l-.195%2034.612c.065%205.774-6.755%208.305-9.612%208.37s-9.678-1.038-9.743-9.408%207.128-9.521%208.362-9.521c1.413-.13%202.526-.021%203.718-.016%202.071.009%204.157-.778%204.092-4.671s-4.157-4.736-4.157-4.736c-6.3-.843-11.43%202.206-11.43%202.206S40.917%2038.15%2041.372%2049.634%2051.568%2068.19%2061.311%2068.125s18.316-7.007%2018.445-17.193l.13-22.772c.046-2.291%202.683-3.644%204.476-4.203.745-.232%201.694-.274%201.694-.274l10.457-.13s4.871-.324%207.729-3.114%204.352-6.294%204.352-6.294.974-3.049.13-4.606-.195-1.233-2.792-3.309-8.573-4.477-8.573-4.477S91.447-.063%2087.81.002zM0%2047.169l.065%2028.417S0%2080.127%204.481%2079.997s5.072-3.866%205.049-4.152l-.113-28.482s1.624-7.656%209.937-7.721%2010.002%206.942%2010.002%208.499-.909%2010.51-9.093%2010.51c-.948%200-2.99-.567-4.145-.272-3.919%201-3.194%204.554-3.194%204.554s.065%205.061%207.404%204.996%2018.575-6.034%2018.575-19.074S26.953%2030.04%2019.549%2029.91%201.234%2035.296%200%2047.169z%22%20fill%3D%22%23198754%22/%3E%3Cg%20transform%3D%22matrix%28.325601%200%200%20.325256%20-10.32669%20-45.802786%29%22%3E%3Ccircle%20cx%3D%22297.554%22%20cy%3D%22172.286%22%20r%3D%2216.5%22%20fill%3D%22%23fff%22/%3E%3Cellipse%20cx%3D%22297.709%22%20cy%3D%22172.642%22%20rx%3D%2211.071%22%20ry%3D%2210.871%22%20fill%3D%22%23105a48%22/%3E%3Ccircle%20cx%3D%22304.104%22%20cy%3D%22167.667%22%20r%3D%224.5%22%20fill%3D%22%23fff%22/%3E%3C/g%3E%3Cpath%20d%3D%22M94.661%2017.032l.893-1.476s.99.714%201.916.925%201.575.114%202.955.114l14.565-.162c1.283-.032%203.085-.762%203.02-3.293s-.373-3.503-.373-3.503l1.283-.487s.52.503.877%201.573.309%201.995.292%202.66-.227%201.541-.227%201.541%201.564-.308%202.359-1.038.823-.779%201.489-1.508.812-.86.812-.86.552-.13.877.26.341.957.065%201.46-1.672%202.206-3.247%203.066-2.76%201.427-3.929%201.768-3.848.73-7.063.714l-10.944-.114s-2.143-.081-3.02-.373-2.241-.973-2.598-1.265z%22%20fill%3D%22%23d36d49%22/%3E%3Cg%20fill%3D%22%23105a48%22%3E%3Cellipse%20cx%3D%2293.052%22%20cy%3D%2243.567%22%20rx%3D%22.869%22%20ry%3D%221.014%22%20transform%3D%22rotate%28341.022%29%22/%3E%3Cellipse%20cx%3D%22104.3%22%20cy%3D%22-16.184%22%20rx%3D%22.865%22%20ry%3D%221.009%22%20transform%3D%22rotate%2814.786%29%22/%3E%3C/g%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../../divisor.html">divisor</a><wbr>.<a href="./../trado.html">trado</a><wbr>.tokenization_qwen2    </h1>

                        <div class="docstring"><p>Tokenization classes for Qwen2.</p>
</div>

                        <input id="mod-tokenization_qwen2-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-tokenization_qwen2-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">  1</span></a><span class="c1"># coding=utf-8</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">  2</span></a><span class="c1"># Copyright 2024 The Qwen team, Alibaba Group and The HuggingFace Inc. team. All rights reserved.</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos">  3</span></a><span class="c1">#</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos">  4</span></a><span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos">  5</span></a><span class="c1"># you may not use this file except in compliance with the License.</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos">  6</span></a><span class="c1"># You may obtain a copy of the License at</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos">  7</span></a><span class="c1">#</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos">  8</span></a><span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos">  9</span></a><span class="c1">#</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos"> 10</span></a><span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos"> 11</span></a><span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos"> 12</span></a><span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos"> 13</span></a><span class="c1"># See the License for the specific language governing permissions and</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos"> 14</span></a><span class="c1"># limitations under the License.</span>
</span><span id="L-15"><a href="#L-15"><span class="linenos"> 15</span></a><span class="sd">&quot;&quot;&quot;Tokenization classes for Qwen2.&quot;&quot;&quot;</span>
</span><span id="L-16"><a href="#L-16"><span class="linenos"> 16</span></a>
</span><span id="L-17"><a href="#L-17"><span class="linenos"> 17</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
</span><span id="L-18"><a href="#L-18"><span class="linenos"> 18</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
</span><span id="L-19"><a href="#L-19"><span class="linenos"> 19</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">unicodedata</span>
</span><span id="L-20"><a href="#L-20"><span class="linenos"> 20</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">lru_cache</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos"> 21</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span>
</span><span id="L-22"><a href="#L-22"><span class="linenos"> 22</span></a>
</span><span id="L-23"><a href="#L-23"><span class="linenos"> 23</span></a><span class="kn">import</span><span class="w"> </span><span class="nn">regex</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">re</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos"> 24</span></a>
</span><span id="L-25"><a href="#L-25"><span class="linenos"> 25</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AddedToken</span><span class="p">,</span> <span class="n">PreTrainedTokenizer</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos"> 26</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">logging</span>
</span><span id="L-27"><a href="#L-27"><span class="linenos"> 27</span></a>
</span><span id="L-28"><a href="#L-28"><span class="linenos"> 28</span></a>
</span><span id="L-29"><a href="#L-29"><span class="linenos"> 29</span></a><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">get_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="L-30"><a href="#L-30"><span class="linenos"> 30</span></a>
</span><span id="L-31"><a href="#L-31"><span class="linenos"> 31</span></a><span class="n">VOCAB_FILES_NAMES</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="L-32"><a href="#L-32"><span class="linenos"> 32</span></a>    <span class="s2">&quot;vocab_file&quot;</span><span class="p">:</span> <span class="s2">&quot;vocab.json&quot;</span><span class="p">,</span>
</span><span id="L-33"><a href="#L-33"><span class="linenos"> 33</span></a>    <span class="s2">&quot;merges_file&quot;</span><span class="p">:</span> <span class="s2">&quot;merges.txt&quot;</span><span class="p">,</span>
</span><span id="L-34"><a href="#L-34"><span class="linenos"> 34</span></a><span class="p">}</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos"> 35</span></a>
</span><span id="L-36"><a href="#L-36"><span class="linenos"> 36</span></a>
</span><span id="L-37"><a href="#L-37"><span class="linenos"> 37</span></a><span class="n">MAX_MODEL_INPUT_SIZES</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;qwen/qwen-tokenizer&quot;</span><span class="p">:</span> <span class="mi">32768</span><span class="p">}</span>
</span><span id="L-38"><a href="#L-38"><span class="linenos"> 38</span></a>
</span><span id="L-39"><a href="#L-39"><span class="linenos"> 39</span></a><span class="n">PRETOKENIZE_REGEX</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;&quot;&quot;(?i:&#39;s|&#39;t|&#39;re|&#39;ve|&#39;m|&#39;ll|&#39;d)|[^\r\n\p</span><span class="si">{L}</span><span class="s2">\p</span><span class="si">{N}</span><span class="s2">]?\p</span><span class="si">{L}</span><span class="s2">+|\p</span><span class="si">{N}</span><span class="s2">| ?[^\s\p</span><span class="si">{L}</span><span class="s2">\p</span><span class="si">{N}</span><span class="s2">]+[\r\n]*|\s*[\r\n]+|\s+(?!\S)|\s+&quot;&quot;&quot;</span>
</span><span id="L-40"><a href="#L-40"><span class="linenos"> 40</span></a>
</span><span id="L-41"><a href="#L-41"><span class="linenos"> 41</span></a>
</span><span id="L-42"><a href="#L-42"><span class="linenos"> 42</span></a><span class="nd">@lru_cache</span><span class="p">()</span>
</span><span id="L-43"><a href="#L-43"><span class="linenos"> 43</span></a><span class="c1"># Copied from transformers.models.gpt2.tokenization_gpt2.bytes_to_unicode</span>
</span><span id="L-44"><a href="#L-44"><span class="linenos"> 44</span></a><span class="k">def</span><span class="w"> </span><span class="nf">bytes_to_unicode</span><span class="p">():</span>
</span><span id="L-45"><a href="#L-45"><span class="linenos"> 45</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-46"><a href="#L-46"><span class="linenos"> 46</span></a><span class="sd">    Returns list of utf-8 byte and a mapping to unicode strings. We specifically avoids mapping to whitespace/control</span>
</span><span id="L-47"><a href="#L-47"><span class="linenos"> 47</span></a><span class="sd">    characters the bpe code barfs on.</span>
</span><span id="L-48"><a href="#L-48"><span class="linenos"> 48</span></a><span class="sd">    The reversible bpe codes work on unicode strings. This means you need a large # of unicode characters in your vocab</span>
</span><span id="L-49"><a href="#L-49"><span class="linenos"> 49</span></a><span class="sd">    if you want to avoid UNKs. When you&#39;re at something like a 10B token dataset you end up needing around 5K for</span>
</span><span id="L-50"><a href="#L-50"><span class="linenos"> 50</span></a><span class="sd">    decent coverage. This is a significant percentage of your normal, say, 32K bpe vocab. To avoid that, we want lookup</span>
</span><span id="L-51"><a href="#L-51"><span class="linenos"> 51</span></a><span class="sd">    tables between utf-8 bytes and unicode strings.</span>
</span><span id="L-52"><a href="#L-52"><span class="linenos"> 52</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-53"><a href="#L-53"><span class="linenos"> 53</span></a>    <span class="n">bs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;!&quot;</span><span class="p">),</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;~&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;¡&quot;</span><span class="p">),</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;¬&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;®&quot;</span><span class="p">),</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;ÿ&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="L-54"><a href="#L-54"><span class="linenos"> 54</span></a>    <span class="n">cs</span> <span class="o">=</span> <span class="n">bs</span><span class="p">[:]</span>
</span><span id="L-55"><a href="#L-55"><span class="linenos"> 55</span></a>    <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-56"><a href="#L-56"><span class="linenos"> 56</span></a>    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">8</span><span class="p">):</span>
</span><span id="L-57"><a href="#L-57"><span class="linenos"> 57</span></a>        <span class="k">if</span> <span class="n">b</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">bs</span><span class="p">:</span>
</span><span id="L-58"><a href="#L-58"><span class="linenos"> 58</span></a>            <span class="n">bs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</span><span id="L-59"><a href="#L-59"><span class="linenos"> 59</span></a>            <span class="n">cs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">8</span> <span class="o">+</span> <span class="n">n</span><span class="p">)</span>
</span><span id="L-60"><a href="#L-60"><span class="linenos"> 60</span></a>            <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="L-61"><a href="#L-61"><span class="linenos"> 61</span></a>    <span class="n">cs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">chr</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">cs</span><span class="p">]</span>
</span><span id="L-62"><a href="#L-62"><span class="linenos"> 62</span></a>    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">cs</span><span class="p">))</span>
</span><span id="L-63"><a href="#L-63"><span class="linenos"> 63</span></a>
</span><span id="L-64"><a href="#L-64"><span class="linenos"> 64</span></a>
</span><span id="L-65"><a href="#L-65"><span class="linenos"> 65</span></a><span class="c1"># Copied from transformers.models.gpt2.tokenization_gpt2.get_pairs</span>
</span><span id="L-66"><a href="#L-66"><span class="linenos"> 66</span></a><span class="k">def</span><span class="w"> </span><span class="nf">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
</span><span id="L-67"><a href="#L-67"><span class="linenos"> 67</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-68"><a href="#L-68"><span class="linenos"> 68</span></a><span class="sd">    Return set of symbol pairs in a word.</span>
</span><span id="L-69"><a href="#L-69"><span class="linenos"> 69</span></a><span class="sd">    Word is represented as tuple of symbols (symbols being variable-length strings).</span>
</span><span id="L-70"><a href="#L-70"><span class="linenos"> 70</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-71"><a href="#L-71"><span class="linenos"> 71</span></a>    <span class="n">pairs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
</span><span id="L-72"><a href="#L-72"><span class="linenos"> 72</span></a>    <span class="n">prev_char</span> <span class="o">=</span> <span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-73"><a href="#L-73"><span class="linenos"> 73</span></a>    <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">word</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
</span><span id="L-74"><a href="#L-74"><span class="linenos"> 74</span></a>        <span class="n">pairs</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">prev_char</span><span class="p">,</span> <span class="n">char</span><span class="p">))</span>
</span><span id="L-75"><a href="#L-75"><span class="linenos"> 75</span></a>        <span class="n">prev_char</span> <span class="o">=</span> <span class="n">char</span>
</span><span id="L-76"><a href="#L-76"><span class="linenos"> 76</span></a>    <span class="k">return</span> <span class="n">pairs</span>
</span><span id="L-77"><a href="#L-77"><span class="linenos"> 77</span></a>
</span><span id="L-78"><a href="#L-78"><span class="linenos"> 78</span></a>
</span><span id="L-79"><a href="#L-79"><span class="linenos"> 79</span></a><span class="k">class</span><span class="w"> </span><span class="nc">Qwen2Tokenizer</span><span class="p">(</span><span class="n">PreTrainedTokenizer</span><span class="p">):</span>
</span><span id="L-80"><a href="#L-80"><span class="linenos"> 80</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-81"><a href="#L-81"><span class="linenos"> 81</span></a><span class="sd">    Construct a Qwen2 tokenizer. Based on byte-level Byte-Pair-Encoding.</span>
</span><span id="L-82"><a href="#L-82"><span class="linenos"> 82</span></a><span class="sd">    Same with GPT2Tokenizer, this tokenizer has been trained to treat spaces like parts of the tokens so a word will</span>
</span><span id="L-83"><a href="#L-83"><span class="linenos"> 83</span></a><span class="sd">    be encoded differently whether it is at the beginning of the sentence (without space) or not:</span>
</span><span id="L-84"><a href="#L-84"><span class="linenos"> 84</span></a><span class="sd">    ```python</span>
</span><span id="L-85"><a href="#L-85"><span class="linenos"> 85</span></a><span class="sd">    &gt;&gt;&gt; from transformers import Qwen2Tokenizer</span>
</span><span id="L-86"><a href="#L-86"><span class="linenos"> 86</span></a><span class="sd">    &gt;&gt;&gt; tokenizer = Qwen2Tokenizer.from_pretrained(&quot;Qwen/Qwen-tokenizer&quot;)</span>
</span><span id="L-87"><a href="#L-87"><span class="linenos"> 87</span></a><span class="sd">    &gt;&gt;&gt; tokenizer(&quot;Hello world&quot;)[&quot;input_ids&quot;]</span>
</span><span id="L-88"><a href="#L-88"><span class="linenos"> 88</span></a><span class="sd">    [9707, 1879]</span>
</span><span id="L-89"><a href="#L-89"><span class="linenos"> 89</span></a><span class="sd">    &gt;&gt;&gt; tokenizer(&quot; Hello world&quot;)[&quot;input_ids&quot;]</span>
</span><span id="L-90"><a href="#L-90"><span class="linenos"> 90</span></a><span class="sd">    [21927, 1879]</span>
</span><span id="L-91"><a href="#L-91"><span class="linenos"> 91</span></a><span class="sd">    ```</span>
</span><span id="L-92"><a href="#L-92"><span class="linenos"> 92</span></a><span class="sd">    This is expected.</span>
</span><span id="L-93"><a href="#L-93"><span class="linenos"> 93</span></a><span class="sd">    You should not use GPT2Tokenizer instead, because of the different pretokenization rules.</span>
</span><span id="L-94"><a href="#L-94"><span class="linenos"> 94</span></a><span class="sd">    This tokenizer inherits from [`PreTrainedTokenizer`] which contains most of the main methods. Users should refer to</span>
</span><span id="L-95"><a href="#L-95"><span class="linenos"> 95</span></a><span class="sd">    this superclass for more information regarding those methods.</span>
</span><span id="L-96"><a href="#L-96"><span class="linenos"> 96</span></a><span class="sd">    Args:</span>
</span><span id="L-97"><a href="#L-97"><span class="linenos"> 97</span></a><span class="sd">        vocab_file (`str`):</span>
</span><span id="L-98"><a href="#L-98"><span class="linenos"> 98</span></a><span class="sd">            Path to the vocabulary file.</span>
</span><span id="L-99"><a href="#L-99"><span class="linenos"> 99</span></a><span class="sd">        merges_file (`str`):</span>
</span><span id="L-100"><a href="#L-100"><span class="linenos">100</span></a><span class="sd">            Path to the merges file.</span>
</span><span id="L-101"><a href="#L-101"><span class="linenos">101</span></a><span class="sd">        errors (`str`, *optional*, defaults to `&quot;replace&quot;`):</span>
</span><span id="L-102"><a href="#L-102"><span class="linenos">102</span></a><span class="sd">            Paradigm to follow when decoding bytes to UTF-8. See</span>
</span><span id="L-103"><a href="#L-103"><span class="linenos">103</span></a><span class="sd">            [bytes.decode](https://docs.python.org/3/library/stdtypes.html#bytes.decode) for more information.</span>
</span><span id="L-104"><a href="#L-104"><span class="linenos">104</span></a><span class="sd">        unk_token (`str`, *optional*, defaults to `&quot;&lt;|endoftext|&gt;&quot;`):</span>
</span><span id="L-105"><a href="#L-105"><span class="linenos">105</span></a><span class="sd">            The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this</span>
</span><span id="L-106"><a href="#L-106"><span class="linenos">106</span></a><span class="sd">            token instead.</span>
</span><span id="L-107"><a href="#L-107"><span class="linenos">107</span></a><span class="sd">        bos_token (`str`, *optional*):</span>
</span><span id="L-108"><a href="#L-108"><span class="linenos">108</span></a><span class="sd">            The beginning of sequence token. Not applicable for this tokenizer.</span>
</span><span id="L-109"><a href="#L-109"><span class="linenos">109</span></a><span class="sd">        eos_token (`str`, *optional*, defaults to `&quot;&lt;|endoftext|&gt;&quot;`):</span>
</span><span id="L-110"><a href="#L-110"><span class="linenos">110</span></a><span class="sd">            The end of sequence token.</span>
</span><span id="L-111"><a href="#L-111"><span class="linenos">111</span></a><span class="sd">        pad_token (`str`, *optional*, defaults to `&quot;&lt;|endoftext|&gt;&quot;`):</span>
</span><span id="L-112"><a href="#L-112"><span class="linenos">112</span></a><span class="sd">            The token used for padding, for example when batching sequences of different lengths.</span>
</span><span id="L-113"><a href="#L-113"><span class="linenos">113</span></a><span class="sd">        clean_up_tokenization_spaces (`bool`, *optional*, defaults to `False`):</span>
</span><span id="L-114"><a href="#L-114"><span class="linenos">114</span></a><span class="sd">            Whether or not the model should cleanup the spaces that were added when splitting the input text during the</span>
</span><span id="L-115"><a href="#L-115"><span class="linenos">115</span></a><span class="sd">            tokenization process. Not applicable to this tokenizer, since tokenization does not add spaces.</span>
</span><span id="L-116"><a href="#L-116"><span class="linenos">116</span></a><span class="sd">        split_special_tokens (`bool`, *optional*, defaults to `False`):</span>
</span><span id="L-117"><a href="#L-117"><span class="linenos">117</span></a><span class="sd">            Whether or not the special tokens should be split during the tokenization process. The default behavior is</span>
</span><span id="L-118"><a href="#L-118"><span class="linenos">118</span></a><span class="sd">            to not split special tokens. This means that if `&lt;|endoftext|&gt;` is the `eos_token`, then `tokenizer.tokenize(&quot;&lt;|endoftext|&gt;&quot;) =</span>
</span><span id="L-119"><a href="#L-119"><span class="linenos">119</span></a><span class="sd">            [&#39;&lt;|endoftext|&gt;`]. Otherwise, if `split_special_tokens=True`, then `tokenizer.tokenize(&quot;&lt;|endoftext|&gt;&quot;)` will be give `[&#39;&lt;&#39;,</span>
</span><span id="L-120"><a href="#L-120"><span class="linenos">120</span></a><span class="sd">            &#39;|&#39;, &#39;endo&#39;, &#39;ft&#39;, &#39;ext&#39;, &#39;|&#39;, &#39;&gt;&#39;]`. This argument is only supported for `slow` tokenizers for the moment.</span>
</span><span id="L-121"><a href="#L-121"><span class="linenos">121</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-122"><a href="#L-122"><span class="linenos">122</span></a>
</span><span id="L-123"><a href="#L-123"><span class="linenos">123</span></a>    <span class="n">vocab_files_names</span> <span class="o">=</span> <span class="n">VOCAB_FILES_NAMES</span>
</span><span id="L-124"><a href="#L-124"><span class="linenos">124</span></a>    <span class="n">model_input_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
</span><span id="L-125"><a href="#L-125"><span class="linenos">125</span></a>
</span><span id="L-126"><a href="#L-126"><span class="linenos">126</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="L-127"><a href="#L-127"><span class="linenos">127</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-128"><a href="#L-128"><span class="linenos">128</span></a>        <span class="n">vocab_file</span><span class="p">,</span>
</span><span id="L-129"><a href="#L-129"><span class="linenos">129</span></a>        <span class="n">merges_file</span><span class="p">,</span>
</span><span id="L-130"><a href="#L-130"><span class="linenos">130</span></a>        <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;replace&quot;</span><span class="p">,</span>
</span><span id="L-131"><a href="#L-131"><span class="linenos">131</span></a>        <span class="n">unk_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
</span><span id="L-132"><a href="#L-132"><span class="linenos">132</span></a>        <span class="n">bos_token</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="L-133"><a href="#L-133"><span class="linenos">133</span></a>        <span class="n">eos_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
</span><span id="L-134"><a href="#L-134"><span class="linenos">134</span></a>        <span class="n">pad_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
</span><span id="L-135"><a href="#L-135"><span class="linenos">135</span></a>        <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-136"><a href="#L-136"><span class="linenos">136</span></a>        <span class="n">split_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="L-137"><a href="#L-137"><span class="linenos">137</span></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="L-138"><a href="#L-138"><span class="linenos">138</span></a>    <span class="p">):</span>
</span><span id="L-139"><a href="#L-139"><span class="linenos">139</span></a>        <span class="c1"># Qwen vocab does not contain control tokens; added tokens need to be special</span>
</span><span id="L-140"><a href="#L-140"><span class="linenos">140</span></a>        <span class="n">bos_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">bos_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">special</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bos_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">bos_token</span>
</span><span id="L-141"><a href="#L-141"><span class="linenos">141</span></a>        <span class="n">eos_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">eos_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">special</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">eos_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">eos_token</span>
</span><span id="L-142"><a href="#L-142"><span class="linenos">142</span></a>        <span class="n">unk_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">unk_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">special</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">unk_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">unk_token</span>
</span><span id="L-143"><a href="#L-143"><span class="linenos">143</span></a>        <span class="n">pad_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">pad_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">special</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pad_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">pad_token</span>
</span><span id="L-144"><a href="#L-144"><span class="linenos">144</span></a>
</span><span id="L-145"><a href="#L-145"><span class="linenos">145</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">vocab_handle</span><span class="p">:</span>
</span><span id="L-146"><a href="#L-146"><span class="linenos">146</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">vocab_handle</span><span class="p">)</span>
</span><span id="L-147"><a href="#L-147"><span class="linenos">147</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span id="L-148"><a href="#L-148"><span class="linenos">148</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">errors</span> <span class="o">=</span> <span class="n">errors</span>  <span class="c1"># how to handle errors in decoding</span>
</span><span id="L-149"><a href="#L-149"><span class="linenos">149</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span> <span class="o">=</span> <span class="n">bytes_to_unicode</span><span class="p">()</span>
</span><span id="L-150"><a href="#L-150"><span class="linenos">150</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span id="L-151"><a href="#L-151"><span class="linenos">151</span></a>        <span class="n">bpe_merges</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-152"><a href="#L-152"><span class="linenos">152</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">merges_file</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">merges_handle</span><span class="p">:</span>
</span><span id="L-153"><a href="#L-153"><span class="linenos">153</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">merges_handle</span><span class="p">):</span>
</span><span id="L-154"><a href="#L-154"><span class="linenos">154</span></a>                <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</span><span id="L-155"><a href="#L-155"><span class="linenos">155</span></a>                <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;#version:&quot;</span><span class="p">))</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">line</span><span class="p">:</span>
</span><span id="L-156"><a href="#L-156"><span class="linenos">156</span></a>                    <span class="k">continue</span>
</span><span id="L-157"><a href="#L-157"><span class="linenos">157</span></a>                <span class="n">bpe_merges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span>
</span><span id="L-158"><a href="#L-158"><span class="linenos">158</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">bpe_merges</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bpe_merges</span><span class="p">))))</span>
</span><span id="L-159"><a href="#L-159"><span class="linenos">159</span></a>        <span class="c1"># NOTE: the cache can grow without bound and will get really large for long running processes</span>
</span><span id="L-160"><a href="#L-160"><span class="linenos">160</span></a>        <span class="c1"># (esp. for texts of language that do not use space between word, e.g. Chinese); technically</span>
</span><span id="L-161"><a href="#L-161"><span class="linenos">161</span></a>        <span class="c1"># not a memory leak but appears as one.</span>
</span><span id="L-162"><a href="#L-162"><span class="linenos">162</span></a>        <span class="c1"># GPT2Tokenizer has the same problem, so let&#39;s be consistent.</span>
</span><span id="L-163"><a href="#L-163"><span class="linenos">163</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-164"><a href="#L-164"><span class="linenos">164</span></a>
</span><span id="L-165"><a href="#L-165"><span class="linenos">165</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pat</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">PRETOKENIZE_REGEX</span><span class="p">)</span>
</span><span id="L-166"><a href="#L-166"><span class="linenos">166</span></a>
</span><span id="L-167"><a href="#L-167"><span class="linenos">167</span></a>        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;add_prefix_space&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="L-168"><a href="#L-168"><span class="linenos">168</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">warning_once</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">__name</span><span class="si">}</span><span class="s2"> does not support `add_prefix_space`, setting it to True has no effect.&quot;</span><span class="p">)</span>
</span><span id="L-169"><a href="#L-169"><span class="linenos">169</span></a>
</span><span id="L-170"><a href="#L-170"><span class="linenos">170</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="L-171"><a href="#L-171"><span class="linenos">171</span></a>            <span class="n">errors</span><span class="o">=</span><span class="n">errors</span><span class="p">,</span>
</span><span id="L-172"><a href="#L-172"><span class="linenos">172</span></a>            <span class="n">bos_token</span><span class="o">=</span><span class="n">bos_token</span><span class="p">,</span>
</span><span id="L-173"><a href="#L-173"><span class="linenos">173</span></a>            <span class="n">eos_token</span><span class="o">=</span><span class="n">eos_token</span><span class="p">,</span>
</span><span id="L-174"><a href="#L-174"><span class="linenos">174</span></a>            <span class="n">pad_token</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span>
</span><span id="L-175"><a href="#L-175"><span class="linenos">175</span></a>            <span class="n">unk_token</span><span class="o">=</span><span class="n">unk_token</span><span class="p">,</span>
</span><span id="L-176"><a href="#L-176"><span class="linenos">176</span></a>            <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="n">clean_up_tokenization_spaces</span><span class="p">,</span>
</span><span id="L-177"><a href="#L-177"><span class="linenos">177</span></a>            <span class="n">split_special_tokens</span><span class="o">=</span><span class="n">split_special_tokens</span><span class="p">,</span>
</span><span id="L-178"><a href="#L-178"><span class="linenos">178</span></a>            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="L-179"><a href="#L-179"><span class="linenos">179</span></a>        <span class="p">)</span>
</span><span id="L-180"><a href="#L-180"><span class="linenos">180</span></a>
</span><span id="L-181"><a href="#L-181"><span class="linenos">181</span></a>    <span class="nd">@property</span>
</span><span id="L-182"><a href="#L-182"><span class="linenos">182</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">vocab_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="L-183"><a href="#L-183"><span class="linenos">183</span></a>        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">)</span>
</span><span id="L-184"><a href="#L-184"><span class="linenos">184</span></a>
</span><span id="L-185"><a href="#L-185"><span class="linenos">185</span></a>    <span class="c1"># Copied from transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer.get_vocab</span>
</span><span id="L-186"><a href="#L-186"><span class="linenos">186</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-187"><a href="#L-187"><span class="linenos">187</span></a>        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">added_tokens_encoder</span><span class="p">)</span>
</span><span id="L-188"><a href="#L-188"><span class="linenos">188</span></a>
</span><span id="L-189"><a href="#L-189"><span class="linenos">189</span></a>    <span class="c1"># Copied from transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer.bpe</span>
</span><span id="L-190"><a href="#L-190"><span class="linenos">190</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">bpe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
</span><span id="L-191"><a href="#L-191"><span class="linenos">191</span></a>        <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">:</span>
</span><span id="L-192"><a href="#L-192"><span class="linenos">192</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
</span><span id="L-193"><a href="#L-193"><span class="linenos">193</span></a>        <span class="n">word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
</span><span id="L-194"><a href="#L-194"><span class="linenos">194</span></a>        <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="L-195"><a href="#L-195"><span class="linenos">195</span></a>
</span><span id="L-196"><a href="#L-196"><span class="linenos">196</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">pairs</span><span class="p">:</span>
</span><span id="L-197"><a href="#L-197"><span class="linenos">197</span></a>            <span class="k">return</span> <span class="n">token</span>
</span><span id="L-198"><a href="#L-198"><span class="linenos">198</span></a>
</span><span id="L-199"><a href="#L-199"><span class="linenos">199</span></a>        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span><span id="L-200"><a href="#L-200"><span class="linenos">200</span></a>            <span class="n">bigram</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">pair</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">pair</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)))</span>
</span><span id="L-201"><a href="#L-201"><span class="linenos">201</span></a>            <span class="k">if</span> <span class="n">bigram</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="p">:</span>
</span><span id="L-202"><a href="#L-202"><span class="linenos">202</span></a>                <span class="k">break</span>
</span><span id="L-203"><a href="#L-203"><span class="linenos">203</span></a>            <span class="n">first</span><span class="p">,</span> <span class="n">second</span> <span class="o">=</span> <span class="n">bigram</span>
</span><span id="L-204"><a href="#L-204"><span class="linenos">204</span></a>            <span class="n">new_word</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-205"><a href="#L-205"><span class="linenos">205</span></a>            <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-206"><a href="#L-206"><span class="linenos">206</span></a>            <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
</span><span id="L-207"><a href="#L-207"><span class="linenos">207</span></a>                <span class="k">try</span><span class="p">:</span>
</span><span id="L-208"><a href="#L-208"><span class="linenos">208</span></a>                    <span class="n">j</span> <span class="o">=</span> <span class="n">word</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
</span><span id="L-209"><a href="#L-209"><span class="linenos">209</span></a>                <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
</span><span id="L-210"><a href="#L-210"><span class="linenos">210</span></a>                    <span class="n">new_word</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:])</span>
</span><span id="L-211"><a href="#L-211"><span class="linenos">211</span></a>                    <span class="k">break</span>
</span><span id="L-212"><a href="#L-212"><span class="linenos">212</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-213"><a href="#L-213"><span class="linenos">213</span></a>                    <span class="n">new_word</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">j</span><span class="p">])</span>
</span><span id="L-214"><a href="#L-214"><span class="linenos">214</span></a>                    <span class="n">i</span> <span class="o">=</span> <span class="n">j</span>
</span><span id="L-215"><a href="#L-215"><span class="linenos">215</span></a>
</span><span id="L-216"><a href="#L-216"><span class="linenos">216</span></a>                <span class="k">if</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">first</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">second</span><span class="p">:</span>
</span><span id="L-217"><a href="#L-217"><span class="linenos">217</span></a>                    <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">first</span> <span class="o">+</span> <span class="n">second</span><span class="p">)</span>
</span><span id="L-218"><a href="#L-218"><span class="linenos">218</span></a>                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">2</span>
</span><span id="L-219"><a href="#L-219"><span class="linenos">219</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-220"><a href="#L-220"><span class="linenos">220</span></a>                    <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="L-221"><a href="#L-221"><span class="linenos">221</span></a>                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="L-222"><a href="#L-222"><span class="linenos">222</span></a>            <span class="n">new_word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_word</span><span class="p">)</span>
</span><span id="L-223"><a href="#L-223"><span class="linenos">223</span></a>            <span class="n">word</span> <span class="o">=</span> <span class="n">new_word</span>
</span><span id="L-224"><a href="#L-224"><span class="linenos">224</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-225"><a href="#L-225"><span class="linenos">225</span></a>                <span class="k">break</span>
</span><span id="L-226"><a href="#L-226"><span class="linenos">226</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-227"><a href="#L-227"><span class="linenos">227</span></a>                <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="L-228"><a href="#L-228"><span class="linenos">228</span></a>        <span class="n">word</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="L-229"><a href="#L-229"><span class="linenos">229</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
</span><span id="L-230"><a href="#L-230"><span class="linenos">230</span></a>        <span class="k">return</span> <span class="n">word</span>
</span><span id="L-231"><a href="#L-231"><span class="linenos">231</span></a>
</span><span id="L-232"><a href="#L-232"><span class="linenos">232</span></a>    <span class="c1"># Copied from transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer._tokenize</span>
</span><span id="L-233"><a href="#L-233"><span class="linenos">233</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
</span><span id="L-234"><a href="#L-234"><span class="linenos">234</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Tokenize a string.&quot;&quot;&quot;</span>
</span><span id="L-235"><a href="#L-235"><span class="linenos">235</span></a>        <span class="n">bpe_tokens</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-236"><a href="#L-236"><span class="linenos">236</span></a>        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pat</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
</span><span id="L-237"><a href="#L-237"><span class="linenos">237</span></a>            <span class="n">token</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">token</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">))</span>  <span class="c1"># Maps all our bytes to unicode strings, avoiding control tokens of the BPE (spaces in our case)</span>
</span><span id="L-238"><a href="#L-238"><span class="linenos">238</span></a>            <span class="n">bpe_tokens</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">bpe_token</span> <span class="k">for</span> <span class="n">bpe_token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe</span><span class="p">(</span><span class="n">token</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">))</span>
</span><span id="L-239"><a href="#L-239"><span class="linenos">239</span></a>        <span class="k">return</span> <span class="n">bpe_tokens</span>
</span><span id="L-240"><a href="#L-240"><span class="linenos">240</span></a>
</span><span id="L-241"><a href="#L-241"><span class="linenos">241</span></a>    <span class="c1"># Copied from transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer._convert_token_to_id</span>
</span><span id="L-242"><a href="#L-242"><span class="linenos">242</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_convert_token_to_id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
</span><span id="L-243"><a href="#L-243"><span class="linenos">243</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts a token (str) in an id using the vocab.&quot;&quot;&quot;</span>
</span><span id="L-244"><a href="#L-244"><span class="linenos">244</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unk_token</span><span class="p">))</span>
</span><span id="L-245"><a href="#L-245"><span class="linenos">245</span></a>
</span><span id="L-246"><a href="#L-246"><span class="linenos">246</span></a>    <span class="c1"># Copied from transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer._convert_id_to_token</span>
</span><span id="L-247"><a href="#L-247"><span class="linenos">247</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_convert_id_to_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
</span><span id="L-248"><a href="#L-248"><span class="linenos">248</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts an index (integer) in a token (str) using the vocab.&quot;&quot;&quot;</span>
</span><span id="L-249"><a href="#L-249"><span class="linenos">249</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
</span><span id="L-250"><a href="#L-250"><span class="linenos">250</span></a>
</span><span id="L-251"><a href="#L-251"><span class="linenos">251</span></a>    <span class="c1"># Copied from transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer.convert_tokens_to_string</span>
</span><span id="L-252"><a href="#L-252"><span class="linenos">252</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">convert_tokens_to_string</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
</span><span id="L-253"><a href="#L-253"><span class="linenos">253</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts a sequence of tokens (string) in a single string.&quot;&quot;&quot;</span>
</span><span id="L-254"><a href="#L-254"><span class="linenos">254</span></a>        <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</span><span id="L-255"><a href="#L-255"><span class="linenos">255</span></a>        <span class="n">text</span> <span class="o">=</span> <span class="nb">bytearray</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">text</span><span class="p">])</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">errors</span><span class="p">)</span>
</span><span id="L-256"><a href="#L-256"><span class="linenos">256</span></a>        <span class="k">return</span> <span class="n">text</span>
</span><span id="L-257"><a href="#L-257"><span class="linenos">257</span></a>
</span><span id="L-258"><a href="#L-258"><span class="linenos">258</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span>
</span><span id="L-259"><a href="#L-259"><span class="linenos">259</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="L-260"><a href="#L-260"><span class="linenos">260</span></a>        <span class="n">token_ids</span><span class="p">,</span>
</span><span id="L-261"><a href="#L-261"><span class="linenos">261</span></a>        <span class="n">skip_special_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="L-262"><a href="#L-262"><span class="linenos">262</span></a>        <span class="n">clean_up_tokenization_spaces</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="L-263"><a href="#L-263"><span class="linenos">263</span></a>        <span class="n">spaces_between_special_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="L-264"><a href="#L-264"><span class="linenos">264</span></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="L-265"><a href="#L-265"><span class="linenos">265</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="L-266"><a href="#L-266"><span class="linenos">266</span></a>        <span class="c1"># `spaces_between_special_tokens` defaults to True for _decode in slow tokenizers</span>
</span><span id="L-267"><a href="#L-267"><span class="linenos">267</span></a>        <span class="c1"># and cannot be configured elsewhere, but it should default to False for Qwen2Tokenizer</span>
</span><span id="L-268"><a href="#L-268"><span class="linenos">268</span></a>        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span>
</span><span id="L-269"><a href="#L-269"><span class="linenos">269</span></a>            <span class="n">token_ids</span><span class="p">,</span>
</span><span id="L-270"><a href="#L-270"><span class="linenos">270</span></a>            <span class="n">skip_special_tokens</span><span class="o">=</span><span class="n">skip_special_tokens</span><span class="p">,</span>
</span><span id="L-271"><a href="#L-271"><span class="linenos">271</span></a>            <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="n">clean_up_tokenization_spaces</span><span class="p">,</span>
</span><span id="L-272"><a href="#L-272"><span class="linenos">272</span></a>            <span class="n">spaces_between_special_tokens</span><span class="o">=</span><span class="n">spaces_between_special_tokens</span><span class="p">,</span>
</span><span id="L-273"><a href="#L-273"><span class="linenos">273</span></a>            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="L-274"><a href="#L-274"><span class="linenos">274</span></a>        <span class="p">)</span>
</span><span id="L-275"><a href="#L-275"><span class="linenos">275</span></a>
</span><span id="L-276"><a href="#L-276"><span class="linenos">276</span></a>    <span class="c1"># Copied from transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer.save_vocabulary</span>
</span><span id="L-277"><a href="#L-277"><span class="linenos">277</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save_vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">filename_prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
</span><span id="L-278"><a href="#L-278"><span class="linenos">278</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">save_directory</span><span class="p">):</span>
</span><span id="L-279"><a href="#L-279"><span class="linenos">279</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Vocabulary path (</span><span class="si">{</span><span class="n">save_directory</span><span class="si">}</span><span class="s2">) should be a directory&quot;</span><span class="p">)</span>
</span><span id="L-280"><a href="#L-280"><span class="linenos">280</span></a>            <span class="k">return</span>
</span><span id="L-281"><a href="#L-281"><span class="linenos">281</span></a>        <span class="n">vocab_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="p">(</span><span class="n">filename_prefix</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="k">if</span> <span class="n">filename_prefix</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="n">VOCAB_FILES_NAMES</span><span class="p">[</span><span class="s2">&quot;vocab_file&quot;</span><span class="p">])</span>
</span><span id="L-282"><a href="#L-282"><span class="linenos">282</span></a>        <span class="n">merge_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="p">(</span><span class="n">filename_prefix</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="k">if</span> <span class="n">filename_prefix</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="n">VOCAB_FILES_NAMES</span><span class="p">[</span><span class="s2">&quot;merges_file&quot;</span><span class="p">])</span>
</span><span id="L-283"><a href="#L-283"><span class="linenos">283</span></a>
</span><span id="L-284"><a href="#L-284"><span class="linenos">284</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="L-285"><a href="#L-285"><span class="linenos">285</span></a>            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-286"><a href="#L-286"><span class="linenos">286</span></a>
</span><span id="L-287"><a href="#L-287"><span class="linenos">287</span></a>        <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-288"><a href="#L-288"><span class="linenos">288</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">merge_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
</span><span id="L-289"><a href="#L-289"><span class="linenos">289</span></a>            <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;#version: 0.2</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-290"><a href="#L-290"><span class="linenos">290</span></a>            <span class="k">for</span> <span class="n">bpe_tokens</span><span class="p">,</span> <span class="n">token_index</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">kv</span><span class="p">:</span> <span class="n">kv</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
</span><span id="L-291"><a href="#L-291"><span class="linenos">291</span></a>                <span class="k">if</span> <span class="n">index</span> <span class="o">!=</span> <span class="n">token_index</span><span class="p">:</span>
</span><span id="L-292"><a href="#L-292"><span class="linenos">292</span></a>                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving vocabulary to </span><span class="si">{</span><span class="n">merge_file</span><span class="si">}</span><span class="s2">: BPE merge indices are not consecutive. Please check that the tokenizer is not corrupted!&quot;</span><span class="p">)</span>
</span><span id="L-293"><a href="#L-293"><span class="linenos">293</span></a>                    <span class="n">index</span> <span class="o">=</span> <span class="n">token_index</span>
</span><span id="L-294"><a href="#L-294"><span class="linenos">294</span></a>                <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">bpe_tokens</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="L-295"><a href="#L-295"><span class="linenos">295</span></a>                <span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="L-296"><a href="#L-296"><span class="linenos">296</span></a>
</span><span id="L-297"><a href="#L-297"><span class="linenos">297</span></a>        <span class="k">return</span> <span class="n">vocab_file</span><span class="p">,</span> <span class="n">merge_file</span>
</span><span id="L-298"><a href="#L-298"><span class="linenos">298</span></a>
</span><span id="L-299"><a href="#L-299"><span class="linenos">299</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_for_tokenization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-300"><a href="#L-300"><span class="linenos">300</span></a>        <span class="n">text</span> <span class="o">=</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="s2">&quot;NFC&quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
</span><span id="L-301"><a href="#L-301"><span class="linenos">301</span></a>        <span class="k">return</span> <span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
</span><span id="L-302"><a href="#L-302"><span class="linenos">302</span></a>
</span><span id="L-303"><a href="#L-303"><span class="linenos">303</span></a>
</span><span id="L-304"><a href="#L-304"><span class="linenos">304</span></a><span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Qwen2Tokenizer&quot;</span><span class="p">]</span>
</span></pre></div>


            </section>
                <section id="Qwen2Tokenizer">
                            <input id="Qwen2Tokenizer-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">Qwen2Tokenizer</span><wbr>(<span class="base">transformers.tokenization_utils.PreTrainedTokenizer</span>):

                <label class="view-source-button" for="Qwen2Tokenizer-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Qwen2Tokenizer"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Qwen2Tokenizer-80"><a href="#Qwen2Tokenizer-80"><span class="linenos"> 80</span></a><span class="k">class</span><span class="w"> </span><span class="nc">Qwen2Tokenizer</span><span class="p">(</span><span class="n">PreTrainedTokenizer</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer-81"><a href="#Qwen2Tokenizer-81"><span class="linenos"> 81</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="Qwen2Tokenizer-82"><a href="#Qwen2Tokenizer-82"><span class="linenos"> 82</span></a><span class="sd">    Construct a Qwen2 tokenizer. Based on byte-level Byte-Pair-Encoding.</span>
</span><span id="Qwen2Tokenizer-83"><a href="#Qwen2Tokenizer-83"><span class="linenos"> 83</span></a><span class="sd">    Same with GPT2Tokenizer, this tokenizer has been trained to treat spaces like parts of the tokens so a word will</span>
</span><span id="Qwen2Tokenizer-84"><a href="#Qwen2Tokenizer-84"><span class="linenos"> 84</span></a><span class="sd">    be encoded differently whether it is at the beginning of the sentence (without space) or not:</span>
</span><span id="Qwen2Tokenizer-85"><a href="#Qwen2Tokenizer-85"><span class="linenos"> 85</span></a><span class="sd">    ```python</span>
</span><span id="Qwen2Tokenizer-86"><a href="#Qwen2Tokenizer-86"><span class="linenos"> 86</span></a><span class="sd">    &gt;&gt;&gt; from transformers import Qwen2Tokenizer</span>
</span><span id="Qwen2Tokenizer-87"><a href="#Qwen2Tokenizer-87"><span class="linenos"> 87</span></a><span class="sd">    &gt;&gt;&gt; tokenizer = Qwen2Tokenizer.from_pretrained(&quot;Qwen/Qwen-tokenizer&quot;)</span>
</span><span id="Qwen2Tokenizer-88"><a href="#Qwen2Tokenizer-88"><span class="linenos"> 88</span></a><span class="sd">    &gt;&gt;&gt; tokenizer(&quot;Hello world&quot;)[&quot;input_ids&quot;]</span>
</span><span id="Qwen2Tokenizer-89"><a href="#Qwen2Tokenizer-89"><span class="linenos"> 89</span></a><span class="sd">    [9707, 1879]</span>
</span><span id="Qwen2Tokenizer-90"><a href="#Qwen2Tokenizer-90"><span class="linenos"> 90</span></a><span class="sd">    &gt;&gt;&gt; tokenizer(&quot; Hello world&quot;)[&quot;input_ids&quot;]</span>
</span><span id="Qwen2Tokenizer-91"><a href="#Qwen2Tokenizer-91"><span class="linenos"> 91</span></a><span class="sd">    [21927, 1879]</span>
</span><span id="Qwen2Tokenizer-92"><a href="#Qwen2Tokenizer-92"><span class="linenos"> 92</span></a><span class="sd">    ```</span>
</span><span id="Qwen2Tokenizer-93"><a href="#Qwen2Tokenizer-93"><span class="linenos"> 93</span></a><span class="sd">    This is expected.</span>
</span><span id="Qwen2Tokenizer-94"><a href="#Qwen2Tokenizer-94"><span class="linenos"> 94</span></a><span class="sd">    You should not use GPT2Tokenizer instead, because of the different pretokenization rules.</span>
</span><span id="Qwen2Tokenizer-95"><a href="#Qwen2Tokenizer-95"><span class="linenos"> 95</span></a><span class="sd">    This tokenizer inherits from [`PreTrainedTokenizer`] which contains most of the main methods. Users should refer to</span>
</span><span id="Qwen2Tokenizer-96"><a href="#Qwen2Tokenizer-96"><span class="linenos"> 96</span></a><span class="sd">    this superclass for more information regarding those methods.</span>
</span><span id="Qwen2Tokenizer-97"><a href="#Qwen2Tokenizer-97"><span class="linenos"> 97</span></a><span class="sd">    Args:</span>
</span><span id="Qwen2Tokenizer-98"><a href="#Qwen2Tokenizer-98"><span class="linenos"> 98</span></a><span class="sd">        vocab_file (`str`):</span>
</span><span id="Qwen2Tokenizer-99"><a href="#Qwen2Tokenizer-99"><span class="linenos"> 99</span></a><span class="sd">            Path to the vocabulary file.</span>
</span><span id="Qwen2Tokenizer-100"><a href="#Qwen2Tokenizer-100"><span class="linenos">100</span></a><span class="sd">        merges_file (`str`):</span>
</span><span id="Qwen2Tokenizer-101"><a href="#Qwen2Tokenizer-101"><span class="linenos">101</span></a><span class="sd">            Path to the merges file.</span>
</span><span id="Qwen2Tokenizer-102"><a href="#Qwen2Tokenizer-102"><span class="linenos">102</span></a><span class="sd">        errors (`str`, *optional*, defaults to `&quot;replace&quot;`):</span>
</span><span id="Qwen2Tokenizer-103"><a href="#Qwen2Tokenizer-103"><span class="linenos">103</span></a><span class="sd">            Paradigm to follow when decoding bytes to UTF-8. See</span>
</span><span id="Qwen2Tokenizer-104"><a href="#Qwen2Tokenizer-104"><span class="linenos">104</span></a><span class="sd">            [bytes.decode](https://docs.python.org/3/library/stdtypes.html#bytes.decode) for more information.</span>
</span><span id="Qwen2Tokenizer-105"><a href="#Qwen2Tokenizer-105"><span class="linenos">105</span></a><span class="sd">        unk_token (`str`, *optional*, defaults to `&quot;&lt;|endoftext|&gt;&quot;`):</span>
</span><span id="Qwen2Tokenizer-106"><a href="#Qwen2Tokenizer-106"><span class="linenos">106</span></a><span class="sd">            The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this</span>
</span><span id="Qwen2Tokenizer-107"><a href="#Qwen2Tokenizer-107"><span class="linenos">107</span></a><span class="sd">            token instead.</span>
</span><span id="Qwen2Tokenizer-108"><a href="#Qwen2Tokenizer-108"><span class="linenos">108</span></a><span class="sd">        bos_token (`str`, *optional*):</span>
</span><span id="Qwen2Tokenizer-109"><a href="#Qwen2Tokenizer-109"><span class="linenos">109</span></a><span class="sd">            The beginning of sequence token. Not applicable for this tokenizer.</span>
</span><span id="Qwen2Tokenizer-110"><a href="#Qwen2Tokenizer-110"><span class="linenos">110</span></a><span class="sd">        eos_token (`str`, *optional*, defaults to `&quot;&lt;|endoftext|&gt;&quot;`):</span>
</span><span id="Qwen2Tokenizer-111"><a href="#Qwen2Tokenizer-111"><span class="linenos">111</span></a><span class="sd">            The end of sequence token.</span>
</span><span id="Qwen2Tokenizer-112"><a href="#Qwen2Tokenizer-112"><span class="linenos">112</span></a><span class="sd">        pad_token (`str`, *optional*, defaults to `&quot;&lt;|endoftext|&gt;&quot;`):</span>
</span><span id="Qwen2Tokenizer-113"><a href="#Qwen2Tokenizer-113"><span class="linenos">113</span></a><span class="sd">            The token used for padding, for example when batching sequences of different lengths.</span>
</span><span id="Qwen2Tokenizer-114"><a href="#Qwen2Tokenizer-114"><span class="linenos">114</span></a><span class="sd">        clean_up_tokenization_spaces (`bool`, *optional*, defaults to `False`):</span>
</span><span id="Qwen2Tokenizer-115"><a href="#Qwen2Tokenizer-115"><span class="linenos">115</span></a><span class="sd">            Whether or not the model should cleanup the spaces that were added when splitting the input text during the</span>
</span><span id="Qwen2Tokenizer-116"><a href="#Qwen2Tokenizer-116"><span class="linenos">116</span></a><span class="sd">            tokenization process. Not applicable to this tokenizer, since tokenization does not add spaces.</span>
</span><span id="Qwen2Tokenizer-117"><a href="#Qwen2Tokenizer-117"><span class="linenos">117</span></a><span class="sd">        split_special_tokens (`bool`, *optional*, defaults to `False`):</span>
</span><span id="Qwen2Tokenizer-118"><a href="#Qwen2Tokenizer-118"><span class="linenos">118</span></a><span class="sd">            Whether or not the special tokens should be split during the tokenization process. The default behavior is</span>
</span><span id="Qwen2Tokenizer-119"><a href="#Qwen2Tokenizer-119"><span class="linenos">119</span></a><span class="sd">            to not split special tokens. This means that if `&lt;|endoftext|&gt;` is the `eos_token`, then `tokenizer.tokenize(&quot;&lt;|endoftext|&gt;&quot;) =</span>
</span><span id="Qwen2Tokenizer-120"><a href="#Qwen2Tokenizer-120"><span class="linenos">120</span></a><span class="sd">            [&#39;&lt;|endoftext|&gt;`]. Otherwise, if `split_special_tokens=True`, then `tokenizer.tokenize(&quot;&lt;|endoftext|&gt;&quot;)` will be give `[&#39;&lt;&#39;,</span>
</span><span id="Qwen2Tokenizer-121"><a href="#Qwen2Tokenizer-121"><span class="linenos">121</span></a><span class="sd">            &#39;|&#39;, &#39;endo&#39;, &#39;ft&#39;, &#39;ext&#39;, &#39;|&#39;, &#39;&gt;&#39;]`. This argument is only supported for `slow` tokenizers for the moment.</span>
</span><span id="Qwen2Tokenizer-122"><a href="#Qwen2Tokenizer-122"><span class="linenos">122</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="Qwen2Tokenizer-123"><a href="#Qwen2Tokenizer-123"><span class="linenos">123</span></a>
</span><span id="Qwen2Tokenizer-124"><a href="#Qwen2Tokenizer-124"><span class="linenos">124</span></a>    <span class="n">vocab_files_names</span> <span class="o">=</span> <span class="n">VOCAB_FILES_NAMES</span>
</span><span id="Qwen2Tokenizer-125"><a href="#Qwen2Tokenizer-125"><span class="linenos">125</span></a>    <span class="n">model_input_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">,</span> <span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
</span><span id="Qwen2Tokenizer-126"><a href="#Qwen2Tokenizer-126"><span class="linenos">126</span></a>
</span><span id="Qwen2Tokenizer-127"><a href="#Qwen2Tokenizer-127"><span class="linenos">127</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="Qwen2Tokenizer-128"><a href="#Qwen2Tokenizer-128"><span class="linenos">128</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-129"><a href="#Qwen2Tokenizer-129"><span class="linenos">129</span></a>        <span class="n">vocab_file</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-130"><a href="#Qwen2Tokenizer-130"><span class="linenos">130</span></a>        <span class="n">merges_file</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-131"><a href="#Qwen2Tokenizer-131"><span class="linenos">131</span></a>        <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;replace&quot;</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-132"><a href="#Qwen2Tokenizer-132"><span class="linenos">132</span></a>        <span class="n">unk_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-133"><a href="#Qwen2Tokenizer-133"><span class="linenos">133</span></a>        <span class="n">bos_token</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-134"><a href="#Qwen2Tokenizer-134"><span class="linenos">134</span></a>        <span class="n">eos_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-135"><a href="#Qwen2Tokenizer-135"><span class="linenos">135</span></a>        <span class="n">pad_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-136"><a href="#Qwen2Tokenizer-136"><span class="linenos">136</span></a>        <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-137"><a href="#Qwen2Tokenizer-137"><span class="linenos">137</span></a>        <span class="n">split_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-138"><a href="#Qwen2Tokenizer-138"><span class="linenos">138</span></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-139"><a href="#Qwen2Tokenizer-139"><span class="linenos">139</span></a>    <span class="p">):</span>
</span><span id="Qwen2Tokenizer-140"><a href="#Qwen2Tokenizer-140"><span class="linenos">140</span></a>        <span class="c1"># Qwen vocab does not contain control tokens; added tokens need to be special</span>
</span><span id="Qwen2Tokenizer-141"><a href="#Qwen2Tokenizer-141"><span class="linenos">141</span></a>        <span class="n">bos_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">bos_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">special</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bos_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">bos_token</span>
</span><span id="Qwen2Tokenizer-142"><a href="#Qwen2Tokenizer-142"><span class="linenos">142</span></a>        <span class="n">eos_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">eos_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">special</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">eos_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">eos_token</span>
</span><span id="Qwen2Tokenizer-143"><a href="#Qwen2Tokenizer-143"><span class="linenos">143</span></a>        <span class="n">unk_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">unk_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">special</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">unk_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">unk_token</span>
</span><span id="Qwen2Tokenizer-144"><a href="#Qwen2Tokenizer-144"><span class="linenos">144</span></a>        <span class="n">pad_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">pad_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">special</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pad_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">pad_token</span>
</span><span id="Qwen2Tokenizer-145"><a href="#Qwen2Tokenizer-145"><span class="linenos">145</span></a>
</span><span id="Qwen2Tokenizer-146"><a href="#Qwen2Tokenizer-146"><span class="linenos">146</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">vocab_handle</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-147"><a href="#Qwen2Tokenizer-147"><span class="linenos">147</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">vocab_handle</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-148"><a href="#Qwen2Tokenizer-148"><span class="linenos">148</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span id="Qwen2Tokenizer-149"><a href="#Qwen2Tokenizer-149"><span class="linenos">149</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">errors</span> <span class="o">=</span> <span class="n">errors</span>  <span class="c1"># how to handle errors in decoding</span>
</span><span id="Qwen2Tokenizer-150"><a href="#Qwen2Tokenizer-150"><span class="linenos">150</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span> <span class="o">=</span> <span class="n">bytes_to_unicode</span><span class="p">()</span>
</span><span id="Qwen2Tokenizer-151"><a href="#Qwen2Tokenizer-151"><span class="linenos">151</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span id="Qwen2Tokenizer-152"><a href="#Qwen2Tokenizer-152"><span class="linenos">152</span></a>        <span class="n">bpe_merges</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="Qwen2Tokenizer-153"><a href="#Qwen2Tokenizer-153"><span class="linenos">153</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">merges_file</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">merges_handle</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-154"><a href="#Qwen2Tokenizer-154"><span class="linenos">154</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">merges_handle</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer-155"><a href="#Qwen2Tokenizer-155"><span class="linenos">155</span></a>                <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</span><span id="Qwen2Tokenizer-156"><a href="#Qwen2Tokenizer-156"><span class="linenos">156</span></a>                <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;#version:&quot;</span><span class="p">))</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">line</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-157"><a href="#Qwen2Tokenizer-157"><span class="linenos">157</span></a>                    <span class="k">continue</span>
</span><span id="Qwen2Tokenizer-158"><a href="#Qwen2Tokenizer-158"><span class="linenos">158</span></a>                <span class="n">bpe_merges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span>
</span><span id="Qwen2Tokenizer-159"><a href="#Qwen2Tokenizer-159"><span class="linenos">159</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">bpe_merges</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bpe_merges</span><span class="p">))))</span>
</span><span id="Qwen2Tokenizer-160"><a href="#Qwen2Tokenizer-160"><span class="linenos">160</span></a>        <span class="c1"># NOTE: the cache can grow without bound and will get really large for long running processes</span>
</span><span id="Qwen2Tokenizer-161"><a href="#Qwen2Tokenizer-161"><span class="linenos">161</span></a>        <span class="c1"># (esp. for texts of language that do not use space between word, e.g. Chinese); technically</span>
</span><span id="Qwen2Tokenizer-162"><a href="#Qwen2Tokenizer-162"><span class="linenos">162</span></a>        <span class="c1"># not a memory leak but appears as one.</span>
</span><span id="Qwen2Tokenizer-163"><a href="#Qwen2Tokenizer-163"><span class="linenos">163</span></a>        <span class="c1"># GPT2Tokenizer has the same problem, so let&#39;s be consistent.</span>
</span><span id="Qwen2Tokenizer-164"><a href="#Qwen2Tokenizer-164"><span class="linenos">164</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="Qwen2Tokenizer-165"><a href="#Qwen2Tokenizer-165"><span class="linenos">165</span></a>
</span><span id="Qwen2Tokenizer-166"><a href="#Qwen2Tokenizer-166"><span class="linenos">166</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pat</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">PRETOKENIZE_REGEX</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-167"><a href="#Qwen2Tokenizer-167"><span class="linenos">167</span></a>
</span><span id="Qwen2Tokenizer-168"><a href="#Qwen2Tokenizer-168"><span class="linenos">168</span></a>        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;add_prefix_space&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer-169"><a href="#Qwen2Tokenizer-169"><span class="linenos">169</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">warning_once</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">__name</span><span class="si">}</span><span class="s2"> does not support `add_prefix_space`, setting it to True has no effect.&quot;</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-170"><a href="#Qwen2Tokenizer-170"><span class="linenos">170</span></a>
</span><span id="Qwen2Tokenizer-171"><a href="#Qwen2Tokenizer-171"><span class="linenos">171</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="Qwen2Tokenizer-172"><a href="#Qwen2Tokenizer-172"><span class="linenos">172</span></a>            <span class="n">errors</span><span class="o">=</span><span class="n">errors</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-173"><a href="#Qwen2Tokenizer-173"><span class="linenos">173</span></a>            <span class="n">bos_token</span><span class="o">=</span><span class="n">bos_token</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-174"><a href="#Qwen2Tokenizer-174"><span class="linenos">174</span></a>            <span class="n">eos_token</span><span class="o">=</span><span class="n">eos_token</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-175"><a href="#Qwen2Tokenizer-175"><span class="linenos">175</span></a>            <span class="n">pad_token</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-176"><a href="#Qwen2Tokenizer-176"><span class="linenos">176</span></a>            <span class="n">unk_token</span><span class="o">=</span><span class="n">unk_token</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-177"><a href="#Qwen2Tokenizer-177"><span class="linenos">177</span></a>            <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="n">clean_up_tokenization_spaces</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-178"><a href="#Qwen2Tokenizer-178"><span class="linenos">178</span></a>            <span class="n">split_special_tokens</span><span class="o">=</span><span class="n">split_special_tokens</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-179"><a href="#Qwen2Tokenizer-179"><span class="linenos">179</span></a>            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-180"><a href="#Qwen2Tokenizer-180"><span class="linenos">180</span></a>        <span class="p">)</span>
</span><span id="Qwen2Tokenizer-181"><a href="#Qwen2Tokenizer-181"><span class="linenos">181</span></a>
</span><span id="Qwen2Tokenizer-182"><a href="#Qwen2Tokenizer-182"><span class="linenos">182</span></a>    <span class="nd">@property</span>
</span><span id="Qwen2Tokenizer-183"><a href="#Qwen2Tokenizer-183"><span class="linenos">183</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">vocab_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-184"><a href="#Qwen2Tokenizer-184"><span class="linenos">184</span></a>        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-185"><a href="#Qwen2Tokenizer-185"><span class="linenos">185</span></a>
</span><span id="Qwen2Tokenizer-186"><a href="#Qwen2Tokenizer-186"><span class="linenos">186</span></a>    <span class="c1"># Copied from transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer.get_vocab</span>
</span><span id="Qwen2Tokenizer-187"><a href="#Qwen2Tokenizer-187"><span class="linenos">187</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer-188"><a href="#Qwen2Tokenizer-188"><span class="linenos">188</span></a>        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">added_tokens_encoder</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-189"><a href="#Qwen2Tokenizer-189"><span class="linenos">189</span></a>
</span><span id="Qwen2Tokenizer-190"><a href="#Qwen2Tokenizer-190"><span class="linenos">190</span></a>    <span class="c1"># Copied from transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer.bpe</span>
</span><span id="Qwen2Tokenizer-191"><a href="#Qwen2Tokenizer-191"><span class="linenos">191</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">bpe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer-192"><a href="#Qwen2Tokenizer-192"><span class="linenos">192</span></a>        <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-193"><a href="#Qwen2Tokenizer-193"><span class="linenos">193</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
</span><span id="Qwen2Tokenizer-194"><a href="#Qwen2Tokenizer-194"><span class="linenos">194</span></a>        <span class="n">word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-195"><a href="#Qwen2Tokenizer-195"><span class="linenos">195</span></a>        <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-196"><a href="#Qwen2Tokenizer-196"><span class="linenos">196</span></a>
</span><span id="Qwen2Tokenizer-197"><a href="#Qwen2Tokenizer-197"><span class="linenos">197</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">pairs</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-198"><a href="#Qwen2Tokenizer-198"><span class="linenos">198</span></a>            <span class="k">return</span> <span class="n">token</span>
</span><span id="Qwen2Tokenizer-199"><a href="#Qwen2Tokenizer-199"><span class="linenos">199</span></a>
</span><span id="Qwen2Tokenizer-200"><a href="#Qwen2Tokenizer-200"><span class="linenos">200</span></a>        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-201"><a href="#Qwen2Tokenizer-201"><span class="linenos">201</span></a>            <span class="n">bigram</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">pair</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">pair</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)))</span>
</span><span id="Qwen2Tokenizer-202"><a href="#Qwen2Tokenizer-202"><span class="linenos">202</span></a>            <span class="k">if</span> <span class="n">bigram</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-203"><a href="#Qwen2Tokenizer-203"><span class="linenos">203</span></a>                <span class="k">break</span>
</span><span id="Qwen2Tokenizer-204"><a href="#Qwen2Tokenizer-204"><span class="linenos">204</span></a>            <span class="n">first</span><span class="p">,</span> <span class="n">second</span> <span class="o">=</span> <span class="n">bigram</span>
</span><span id="Qwen2Tokenizer-205"><a href="#Qwen2Tokenizer-205"><span class="linenos">205</span></a>            <span class="n">new_word</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="Qwen2Tokenizer-206"><a href="#Qwen2Tokenizer-206"><span class="linenos">206</span></a>            <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="Qwen2Tokenizer-207"><a href="#Qwen2Tokenizer-207"><span class="linenos">207</span></a>            <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer-208"><a href="#Qwen2Tokenizer-208"><span class="linenos">208</span></a>                <span class="k">try</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-209"><a href="#Qwen2Tokenizer-209"><span class="linenos">209</span></a>                    <span class="n">j</span> <span class="o">=</span> <span class="n">word</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-210"><a href="#Qwen2Tokenizer-210"><span class="linenos">210</span></a>                <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-211"><a href="#Qwen2Tokenizer-211"><span class="linenos">211</span></a>                    <span class="n">new_word</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:])</span>
</span><span id="Qwen2Tokenizer-212"><a href="#Qwen2Tokenizer-212"><span class="linenos">212</span></a>                    <span class="k">break</span>
</span><span id="Qwen2Tokenizer-213"><a href="#Qwen2Tokenizer-213"><span class="linenos">213</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-214"><a href="#Qwen2Tokenizer-214"><span class="linenos">214</span></a>                    <span class="n">new_word</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">j</span><span class="p">])</span>
</span><span id="Qwen2Tokenizer-215"><a href="#Qwen2Tokenizer-215"><span class="linenos">215</span></a>                    <span class="n">i</span> <span class="o">=</span> <span class="n">j</span>
</span><span id="Qwen2Tokenizer-216"><a href="#Qwen2Tokenizer-216"><span class="linenos">216</span></a>
</span><span id="Qwen2Tokenizer-217"><a href="#Qwen2Tokenizer-217"><span class="linenos">217</span></a>                <span class="k">if</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">first</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">second</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-218"><a href="#Qwen2Tokenizer-218"><span class="linenos">218</span></a>                    <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">first</span> <span class="o">+</span> <span class="n">second</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-219"><a href="#Qwen2Tokenizer-219"><span class="linenos">219</span></a>                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">2</span>
</span><span id="Qwen2Tokenizer-220"><a href="#Qwen2Tokenizer-220"><span class="linenos">220</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-221"><a href="#Qwen2Tokenizer-221"><span class="linenos">221</span></a>                    <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="Qwen2Tokenizer-222"><a href="#Qwen2Tokenizer-222"><span class="linenos">222</span></a>                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="Qwen2Tokenizer-223"><a href="#Qwen2Tokenizer-223"><span class="linenos">223</span></a>            <span class="n">new_word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_word</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-224"><a href="#Qwen2Tokenizer-224"><span class="linenos">224</span></a>            <span class="n">word</span> <span class="o">=</span> <span class="n">new_word</span>
</span><span id="Qwen2Tokenizer-225"><a href="#Qwen2Tokenizer-225"><span class="linenos">225</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-226"><a href="#Qwen2Tokenizer-226"><span class="linenos">226</span></a>                <span class="k">break</span>
</span><span id="Qwen2Tokenizer-227"><a href="#Qwen2Tokenizer-227"><span class="linenos">227</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-228"><a href="#Qwen2Tokenizer-228"><span class="linenos">228</span></a>                <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-229"><a href="#Qwen2Tokenizer-229"><span class="linenos">229</span></a>        <span class="n">word</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-230"><a href="#Qwen2Tokenizer-230"><span class="linenos">230</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
</span><span id="Qwen2Tokenizer-231"><a href="#Qwen2Tokenizer-231"><span class="linenos">231</span></a>        <span class="k">return</span> <span class="n">word</span>
</span><span id="Qwen2Tokenizer-232"><a href="#Qwen2Tokenizer-232"><span class="linenos">232</span></a>
</span><span id="Qwen2Tokenizer-233"><a href="#Qwen2Tokenizer-233"><span class="linenos">233</span></a>    <span class="c1"># Copied from transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer._tokenize</span>
</span><span id="Qwen2Tokenizer-234"><a href="#Qwen2Tokenizer-234"><span class="linenos">234</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer-235"><a href="#Qwen2Tokenizer-235"><span class="linenos">235</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Tokenize a string.&quot;&quot;&quot;</span>
</span><span id="Qwen2Tokenizer-236"><a href="#Qwen2Tokenizer-236"><span class="linenos">236</span></a>        <span class="n">bpe_tokens</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="Qwen2Tokenizer-237"><a href="#Qwen2Tokenizer-237"><span class="linenos">237</span></a>        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pat</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer-238"><a href="#Qwen2Tokenizer-238"><span class="linenos">238</span></a>            <span class="n">token</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">token</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">))</span>  <span class="c1"># Maps all our bytes to unicode strings, avoiding control tokens of the BPE (spaces in our case)</span>
</span><span id="Qwen2Tokenizer-239"><a href="#Qwen2Tokenizer-239"><span class="linenos">239</span></a>            <span class="n">bpe_tokens</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">bpe_token</span> <span class="k">for</span> <span class="n">bpe_token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe</span><span class="p">(</span><span class="n">token</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">))</span>
</span><span id="Qwen2Tokenizer-240"><a href="#Qwen2Tokenizer-240"><span class="linenos">240</span></a>        <span class="k">return</span> <span class="n">bpe_tokens</span>
</span><span id="Qwen2Tokenizer-241"><a href="#Qwen2Tokenizer-241"><span class="linenos">241</span></a>
</span><span id="Qwen2Tokenizer-242"><a href="#Qwen2Tokenizer-242"><span class="linenos">242</span></a>    <span class="c1"># Copied from transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer._convert_token_to_id</span>
</span><span id="Qwen2Tokenizer-243"><a href="#Qwen2Tokenizer-243"><span class="linenos">243</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_convert_token_to_id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer-244"><a href="#Qwen2Tokenizer-244"><span class="linenos">244</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts a token (str) in an id using the vocab.&quot;&quot;&quot;</span>
</span><span id="Qwen2Tokenizer-245"><a href="#Qwen2Tokenizer-245"><span class="linenos">245</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unk_token</span><span class="p">))</span>
</span><span id="Qwen2Tokenizer-246"><a href="#Qwen2Tokenizer-246"><span class="linenos">246</span></a>
</span><span id="Qwen2Tokenizer-247"><a href="#Qwen2Tokenizer-247"><span class="linenos">247</span></a>    <span class="c1"># Copied from transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer._convert_id_to_token</span>
</span><span id="Qwen2Tokenizer-248"><a href="#Qwen2Tokenizer-248"><span class="linenos">248</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_convert_id_to_token</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer-249"><a href="#Qwen2Tokenizer-249"><span class="linenos">249</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts an index (integer) in a token (str) using the vocab.&quot;&quot;&quot;</span>
</span><span id="Qwen2Tokenizer-250"><a href="#Qwen2Tokenizer-250"><span class="linenos">250</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-251"><a href="#Qwen2Tokenizer-251"><span class="linenos">251</span></a>
</span><span id="Qwen2Tokenizer-252"><a href="#Qwen2Tokenizer-252"><span class="linenos">252</span></a>    <span class="c1"># Copied from transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer.convert_tokens_to_string</span>
</span><span id="Qwen2Tokenizer-253"><a href="#Qwen2Tokenizer-253"><span class="linenos">253</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">convert_tokens_to_string</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer-254"><a href="#Qwen2Tokenizer-254"><span class="linenos">254</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts a sequence of tokens (string) in a single string.&quot;&quot;&quot;</span>
</span><span id="Qwen2Tokenizer-255"><a href="#Qwen2Tokenizer-255"><span class="linenos">255</span></a>        <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-256"><a href="#Qwen2Tokenizer-256"><span class="linenos">256</span></a>        <span class="n">text</span> <span class="o">=</span> <span class="nb">bytearray</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">text</span><span class="p">])</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">errors</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-257"><a href="#Qwen2Tokenizer-257"><span class="linenos">257</span></a>        <span class="k">return</span> <span class="n">text</span>
</span><span id="Qwen2Tokenizer-258"><a href="#Qwen2Tokenizer-258"><span class="linenos">258</span></a>
</span><span id="Qwen2Tokenizer-259"><a href="#Qwen2Tokenizer-259"><span class="linenos">259</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span>
</span><span id="Qwen2Tokenizer-260"><a href="#Qwen2Tokenizer-260"><span class="linenos">260</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-261"><a href="#Qwen2Tokenizer-261"><span class="linenos">261</span></a>        <span class="n">token_ids</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-262"><a href="#Qwen2Tokenizer-262"><span class="linenos">262</span></a>        <span class="n">skip_special_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-263"><a href="#Qwen2Tokenizer-263"><span class="linenos">263</span></a>        <span class="n">clean_up_tokenization_spaces</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-264"><a href="#Qwen2Tokenizer-264"><span class="linenos">264</span></a>        <span class="n">spaces_between_special_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-265"><a href="#Qwen2Tokenizer-265"><span class="linenos">265</span></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-266"><a href="#Qwen2Tokenizer-266"><span class="linenos">266</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-267"><a href="#Qwen2Tokenizer-267"><span class="linenos">267</span></a>        <span class="c1"># `spaces_between_special_tokens` defaults to True for _decode in slow tokenizers</span>
</span><span id="Qwen2Tokenizer-268"><a href="#Qwen2Tokenizer-268"><span class="linenos">268</span></a>        <span class="c1"># and cannot be configured elsewhere, but it should default to False for Qwen2Tokenizer</span>
</span><span id="Qwen2Tokenizer-269"><a href="#Qwen2Tokenizer-269"><span class="linenos">269</span></a>        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span>
</span><span id="Qwen2Tokenizer-270"><a href="#Qwen2Tokenizer-270"><span class="linenos">270</span></a>            <span class="n">token_ids</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-271"><a href="#Qwen2Tokenizer-271"><span class="linenos">271</span></a>            <span class="n">skip_special_tokens</span><span class="o">=</span><span class="n">skip_special_tokens</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-272"><a href="#Qwen2Tokenizer-272"><span class="linenos">272</span></a>            <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="n">clean_up_tokenization_spaces</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-273"><a href="#Qwen2Tokenizer-273"><span class="linenos">273</span></a>            <span class="n">spaces_between_special_tokens</span><span class="o">=</span><span class="n">spaces_between_special_tokens</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-274"><a href="#Qwen2Tokenizer-274"><span class="linenos">274</span></a>            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer-275"><a href="#Qwen2Tokenizer-275"><span class="linenos">275</span></a>        <span class="p">)</span>
</span><span id="Qwen2Tokenizer-276"><a href="#Qwen2Tokenizer-276"><span class="linenos">276</span></a>
</span><span id="Qwen2Tokenizer-277"><a href="#Qwen2Tokenizer-277"><span class="linenos">277</span></a>    <span class="c1"># Copied from transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer.save_vocabulary</span>
</span><span id="Qwen2Tokenizer-278"><a href="#Qwen2Tokenizer-278"><span class="linenos">278</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save_vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">filename_prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
</span><span id="Qwen2Tokenizer-279"><a href="#Qwen2Tokenizer-279"><span class="linenos">279</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">save_directory</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer-280"><a href="#Qwen2Tokenizer-280"><span class="linenos">280</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Vocabulary path (</span><span class="si">{</span><span class="n">save_directory</span><span class="si">}</span><span class="s2">) should be a directory&quot;</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-281"><a href="#Qwen2Tokenizer-281"><span class="linenos">281</span></a>            <span class="k">return</span>
</span><span id="Qwen2Tokenizer-282"><a href="#Qwen2Tokenizer-282"><span class="linenos">282</span></a>        <span class="n">vocab_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="p">(</span><span class="n">filename_prefix</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="k">if</span> <span class="n">filename_prefix</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="n">VOCAB_FILES_NAMES</span><span class="p">[</span><span class="s2">&quot;vocab_file&quot;</span><span class="p">])</span>
</span><span id="Qwen2Tokenizer-283"><a href="#Qwen2Tokenizer-283"><span class="linenos">283</span></a>        <span class="n">merge_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="p">(</span><span class="n">filename_prefix</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="k">if</span> <span class="n">filename_prefix</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="n">VOCAB_FILES_NAMES</span><span class="p">[</span><span class="s2">&quot;merges_file&quot;</span><span class="p">])</span>
</span><span id="Qwen2Tokenizer-284"><a href="#Qwen2Tokenizer-284"><span class="linenos">284</span></a>
</span><span id="Qwen2Tokenizer-285"><a href="#Qwen2Tokenizer-285"><span class="linenos">285</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-286"><a href="#Qwen2Tokenizer-286"><span class="linenos">286</span></a>            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-287"><a href="#Qwen2Tokenizer-287"><span class="linenos">287</span></a>
</span><span id="Qwen2Tokenizer-288"><a href="#Qwen2Tokenizer-288"><span class="linenos">288</span></a>        <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="Qwen2Tokenizer-289"><a href="#Qwen2Tokenizer-289"><span class="linenos">289</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">merge_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-290"><a href="#Qwen2Tokenizer-290"><span class="linenos">290</span></a>            <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;#version: 0.2</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-291"><a href="#Qwen2Tokenizer-291"><span class="linenos">291</span></a>            <span class="k">for</span> <span class="n">bpe_tokens</span><span class="p">,</span> <span class="n">token_index</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">kv</span><span class="p">:</span> <span class="n">kv</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
</span><span id="Qwen2Tokenizer-292"><a href="#Qwen2Tokenizer-292"><span class="linenos">292</span></a>                <span class="k">if</span> <span class="n">index</span> <span class="o">!=</span> <span class="n">token_index</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer-293"><a href="#Qwen2Tokenizer-293"><span class="linenos">293</span></a>                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving vocabulary to </span><span class="si">{</span><span class="n">merge_file</span><span class="si">}</span><span class="s2">: BPE merge indices are not consecutive. Please check that the tokenizer is not corrupted!&quot;</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-294"><a href="#Qwen2Tokenizer-294"><span class="linenos">294</span></a>                    <span class="n">index</span> <span class="o">=</span> <span class="n">token_index</span>
</span><span id="Qwen2Tokenizer-295"><a href="#Qwen2Tokenizer-295"><span class="linenos">295</span></a>                <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">bpe_tokens</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-296"><a href="#Qwen2Tokenizer-296"><span class="linenos">296</span></a>                <span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="Qwen2Tokenizer-297"><a href="#Qwen2Tokenizer-297"><span class="linenos">297</span></a>
</span><span id="Qwen2Tokenizer-298"><a href="#Qwen2Tokenizer-298"><span class="linenos">298</span></a>        <span class="k">return</span> <span class="n">vocab_file</span><span class="p">,</span> <span class="n">merge_file</span>
</span><span id="Qwen2Tokenizer-299"><a href="#Qwen2Tokenizer-299"><span class="linenos">299</span></a>
</span><span id="Qwen2Tokenizer-300"><a href="#Qwen2Tokenizer-300"><span class="linenos">300</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_for_tokenization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer-301"><a href="#Qwen2Tokenizer-301"><span class="linenos">301</span></a>        <span class="n">text</span> <span class="o">=</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="s2">&quot;NFC&quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer-302"><a href="#Qwen2Tokenizer-302"><span class="linenos">302</span></a>        <span class="k">return</span> <span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Construct a Qwen2 tokenizer. Based on byte-level Byte-Pair-Encoding.
Same with GPT2Tokenizer, this tokenizer has been trained to treat spaces like parts of the tokens so a word will
be encoded differently whether it is at the beginning of the sentence (without space) or not:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Qwen2Tokenizer</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n"><a href="#Qwen2Tokenizer.from_pretrained">Qwen2Tokenizer.from_pretrained</a></span><span class="p">(</span><span class="s2">&quot;Qwen/Qwen-tokenizer&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;Hello world&quot;</span><span class="p">)[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>
<span class="p">[</span><span class="mi">9707</span><span class="p">,</span> <span class="mi">1879</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot; Hello world&quot;</span><span class="p">)[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>
<span class="p">[</span><span class="mi">21927</span><span class="p">,</span> <span class="mi">1879</span><span class="p">]</span>
</code></pre>
</div>

<p>This is expected.
You should not use GPT2Tokenizer instead, because of the different pretokenization rules.
This tokenizer inherits from [<code>PreTrainedTokenizer</code>] which contains most of the main methods. Users should refer to
this superclass for more information regarding those methods.
Args:
    vocab_file (<code>str</code>):
        Path to the vocabulary file.
    merges_file (<code>str</code>):
        Path to the merges file.
    errors (<code>str</code>, <em>optional</em>, defaults to <code>"replace"</code>):
        Paradigm to follow when decoding bytes to UTF-8. See
        <a href="https://docs.python.org/3/library/stdtypes.html#bytes.decode">bytes.decode</a> for more information.
    unk_token (<code>str</code>, *optional*, defaults to <code>"&lt;|endoftext|&gt;"</code>):
        The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this
        token instead.
    bos_token (<code>str</code>, <em>optional</em>):
        The beginning of sequence token. Not applicable for this tokenizer.
    eos_token (<code>str</code>, *optional*, defaults to <code>"&lt;|endoftext|&gt;"</code>):
        The end of sequence token.
    pad_token (<code>str</code>, <em>optional</em>, defaults to <code>"&lt;|endoftext|&gt;"</code>):
        The token used for padding, for example when batching sequences of different lengths.
    clean_up_tokenization_spaces (<code>bool</code>, *optional*, defaults to <code>False</code>):
        Whether or not the model should cleanup the spaces that were added when splitting the input text during the
        tokenization process. Not applicable to this tokenizer, since tokenization does not add spaces.
    split_special_tokens (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):
        Whether or not the special tokens should be split during the tokenization process. The default behavior is
        to not split special tokens. This means that if <code>&lt;|endoftext|&gt;</code> is the <code>eos_token</code>, then <code>tokenizer.tokenize("&lt;|endoftext|&gt;") =
        ['&lt;|endoftext|&gt;</code>]. Otherwise, if <code>split_special_tokens=True</code>, then <code>tokenizer.tokenize("&lt;|endoftext|&gt;")</code> will be give <code>['&lt;',
        '|', 'endo', 'ft', 'ext', '|', '&gt;']</code>. This argument is only supported for <code>slow</code> tokenizers for the moment.</p>
</div>


                            <div id="Qwen2Tokenizer.__init__" class="classattr">
                                        <input id="Qwen2Tokenizer.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">Qwen2Tokenizer</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">vocab_file</span>,</span><span class="param">	<span class="n">merges_file</span>,</span><span class="param">	<span class="n">errors</span><span class="o">=</span><span class="s1">&#39;replace&#39;</span>,</span><span class="param">	<span class="n">unk_token</span><span class="o">=</span><span class="s1">&#39;&lt;|endoftext|&gt;&#39;</span>,</span><span class="param">	<span class="n">bos_token</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">eos_token</span><span class="o">=</span><span class="s1">&#39;&lt;|endoftext|&gt;&#39;</span>,</span><span class="param">	<span class="n">pad_token</span><span class="o">=</span><span class="s1">&#39;&lt;|endoftext|&gt;&#39;</span>,</span><span class="param">	<span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="kc">False</span>,</span><span class="param">	<span class="n">split_special_tokens</span><span class="o">=</span><span class="kc">False</span>,</span><span class="param">	<span class="o">**</span><span class="n">kwargs</span></span>)</span>

                <label class="view-source-button" for="Qwen2Tokenizer.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Qwen2Tokenizer.__init__-127"><a href="#Qwen2Tokenizer.__init__-127"><span class="linenos">127</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="Qwen2Tokenizer.__init__-128"><a href="#Qwen2Tokenizer.__init__-128"><span class="linenos">128</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-129"><a href="#Qwen2Tokenizer.__init__-129"><span class="linenos">129</span></a>        <span class="n">vocab_file</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-130"><a href="#Qwen2Tokenizer.__init__-130"><span class="linenos">130</span></a>        <span class="n">merges_file</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-131"><a href="#Qwen2Tokenizer.__init__-131"><span class="linenos">131</span></a>        <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;replace&quot;</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-132"><a href="#Qwen2Tokenizer.__init__-132"><span class="linenos">132</span></a>        <span class="n">unk_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-133"><a href="#Qwen2Tokenizer.__init__-133"><span class="linenos">133</span></a>        <span class="n">bos_token</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-134"><a href="#Qwen2Tokenizer.__init__-134"><span class="linenos">134</span></a>        <span class="n">eos_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-135"><a href="#Qwen2Tokenizer.__init__-135"><span class="linenos">135</span></a>        <span class="n">pad_token</span><span class="o">=</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-136"><a href="#Qwen2Tokenizer.__init__-136"><span class="linenos">136</span></a>        <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-137"><a href="#Qwen2Tokenizer.__init__-137"><span class="linenos">137</span></a>        <span class="n">split_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-138"><a href="#Qwen2Tokenizer.__init__-138"><span class="linenos">138</span></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-139"><a href="#Qwen2Tokenizer.__init__-139"><span class="linenos">139</span></a>    <span class="p">):</span>
</span><span id="Qwen2Tokenizer.__init__-140"><a href="#Qwen2Tokenizer.__init__-140"><span class="linenos">140</span></a>        <span class="c1"># Qwen vocab does not contain control tokens; added tokens need to be special</span>
</span><span id="Qwen2Tokenizer.__init__-141"><a href="#Qwen2Tokenizer.__init__-141"><span class="linenos">141</span></a>        <span class="n">bos_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">bos_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">special</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bos_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">bos_token</span>
</span><span id="Qwen2Tokenizer.__init__-142"><a href="#Qwen2Tokenizer.__init__-142"><span class="linenos">142</span></a>        <span class="n">eos_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">eos_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">special</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">eos_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">eos_token</span>
</span><span id="Qwen2Tokenizer.__init__-143"><a href="#Qwen2Tokenizer.__init__-143"><span class="linenos">143</span></a>        <span class="n">unk_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">unk_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">special</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">unk_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">unk_token</span>
</span><span id="Qwen2Tokenizer.__init__-144"><a href="#Qwen2Tokenizer.__init__-144"><span class="linenos">144</span></a>        <span class="n">pad_token</span> <span class="o">=</span> <span class="n">AddedToken</span><span class="p">(</span><span class="n">pad_token</span><span class="p">,</span> <span class="n">lstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rstrip</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">special</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pad_token</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">pad_token</span>
</span><span id="Qwen2Tokenizer.__init__-145"><a href="#Qwen2Tokenizer.__init__-145"><span class="linenos">145</span></a>
</span><span id="Qwen2Tokenizer.__init__-146"><a href="#Qwen2Tokenizer.__init__-146"><span class="linenos">146</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">vocab_handle</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.__init__-147"><a href="#Qwen2Tokenizer.__init__-147"><span class="linenos">147</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">vocab_handle</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.__init__-148"><a href="#Qwen2Tokenizer.__init__-148"><span class="linenos">148</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span id="Qwen2Tokenizer.__init__-149"><a href="#Qwen2Tokenizer.__init__-149"><span class="linenos">149</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">errors</span> <span class="o">=</span> <span class="n">errors</span>  <span class="c1"># how to handle errors in decoding</span>
</span><span id="Qwen2Tokenizer.__init__-150"><a href="#Qwen2Tokenizer.__init__-150"><span class="linenos">150</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span> <span class="o">=</span> <span class="n">bytes_to_unicode</span><span class="p">()</span>
</span><span id="Qwen2Tokenizer.__init__-151"><a href="#Qwen2Tokenizer.__init__-151"><span class="linenos">151</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span id="Qwen2Tokenizer.__init__-152"><a href="#Qwen2Tokenizer.__init__-152"><span class="linenos">152</span></a>        <span class="n">bpe_merges</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="Qwen2Tokenizer.__init__-153"><a href="#Qwen2Tokenizer.__init__-153"><span class="linenos">153</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">merges_file</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">merges_handle</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.__init__-154"><a href="#Qwen2Tokenizer.__init__-154"><span class="linenos">154</span></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">merges_handle</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer.__init__-155"><a href="#Qwen2Tokenizer.__init__-155"><span class="linenos">155</span></a>                <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</span><span id="Qwen2Tokenizer.__init__-156"><a href="#Qwen2Tokenizer.__init__-156"><span class="linenos">156</span></a>                <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;#version:&quot;</span><span class="p">))</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">line</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.__init__-157"><a href="#Qwen2Tokenizer.__init__-157"><span class="linenos">157</span></a>                    <span class="k">continue</span>
</span><span id="Qwen2Tokenizer.__init__-158"><a href="#Qwen2Tokenizer.__init__-158"><span class="linenos">158</span></a>                <span class="n">bpe_merges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span>
</span><span id="Qwen2Tokenizer.__init__-159"><a href="#Qwen2Tokenizer.__init__-159"><span class="linenos">159</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">bpe_merges</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bpe_merges</span><span class="p">))))</span>
</span><span id="Qwen2Tokenizer.__init__-160"><a href="#Qwen2Tokenizer.__init__-160"><span class="linenos">160</span></a>        <span class="c1"># NOTE: the cache can grow without bound and will get really large for long running processes</span>
</span><span id="Qwen2Tokenizer.__init__-161"><a href="#Qwen2Tokenizer.__init__-161"><span class="linenos">161</span></a>        <span class="c1"># (esp. for texts of language that do not use space between word, e.g. Chinese); technically</span>
</span><span id="Qwen2Tokenizer.__init__-162"><a href="#Qwen2Tokenizer.__init__-162"><span class="linenos">162</span></a>        <span class="c1"># not a memory leak but appears as one.</span>
</span><span id="Qwen2Tokenizer.__init__-163"><a href="#Qwen2Tokenizer.__init__-163"><span class="linenos">163</span></a>        <span class="c1"># GPT2Tokenizer has the same problem, so let&#39;s be consistent.</span>
</span><span id="Qwen2Tokenizer.__init__-164"><a href="#Qwen2Tokenizer.__init__-164"><span class="linenos">164</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="Qwen2Tokenizer.__init__-165"><a href="#Qwen2Tokenizer.__init__-165"><span class="linenos">165</span></a>
</span><span id="Qwen2Tokenizer.__init__-166"><a href="#Qwen2Tokenizer.__init__-166"><span class="linenos">166</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pat</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">PRETOKENIZE_REGEX</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.__init__-167"><a href="#Qwen2Tokenizer.__init__-167"><span class="linenos">167</span></a>
</span><span id="Qwen2Tokenizer.__init__-168"><a href="#Qwen2Tokenizer.__init__-168"><span class="linenos">168</span></a>        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;add_prefix_space&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer.__init__-169"><a href="#Qwen2Tokenizer.__init__-169"><span class="linenos">169</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">warning_once</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">__name</span><span class="si">}</span><span class="s2"> does not support `add_prefix_space`, setting it to True has no effect.&quot;</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.__init__-170"><a href="#Qwen2Tokenizer.__init__-170"><span class="linenos">170</span></a>
</span><span id="Qwen2Tokenizer.__init__-171"><a href="#Qwen2Tokenizer.__init__-171"><span class="linenos">171</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="Qwen2Tokenizer.__init__-172"><a href="#Qwen2Tokenizer.__init__-172"><span class="linenos">172</span></a>            <span class="n">errors</span><span class="o">=</span><span class="n">errors</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-173"><a href="#Qwen2Tokenizer.__init__-173"><span class="linenos">173</span></a>            <span class="n">bos_token</span><span class="o">=</span><span class="n">bos_token</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-174"><a href="#Qwen2Tokenizer.__init__-174"><span class="linenos">174</span></a>            <span class="n">eos_token</span><span class="o">=</span><span class="n">eos_token</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-175"><a href="#Qwen2Tokenizer.__init__-175"><span class="linenos">175</span></a>            <span class="n">pad_token</span><span class="o">=</span><span class="n">pad_token</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-176"><a href="#Qwen2Tokenizer.__init__-176"><span class="linenos">176</span></a>            <span class="n">unk_token</span><span class="o">=</span><span class="n">unk_token</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-177"><a href="#Qwen2Tokenizer.__init__-177"><span class="linenos">177</span></a>            <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="n">clean_up_tokenization_spaces</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-178"><a href="#Qwen2Tokenizer.__init__-178"><span class="linenos">178</span></a>            <span class="n">split_special_tokens</span><span class="o">=</span><span class="n">split_special_tokens</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-179"><a href="#Qwen2Tokenizer.__init__-179"><span class="linenos">179</span></a>            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.__init__-180"><a href="#Qwen2Tokenizer.__init__-180"><span class="linenos">180</span></a>        <span class="p">)</span>
</span></pre></div>


    

                            </div>
                            <div id="Qwen2Tokenizer.vocab_files_names" class="classattr">
                                <div class="attr variable">
            <span class="name">vocab_files_names</span>        =
<span class="default_value">{&#39;vocab_file&#39;: &#39;vocab.json&#39;, &#39;merges_file&#39;: &#39;merges.txt&#39;}</span>

        
    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.vocab_files_names"></a>
    
    

                            </div>
                            <div id="Qwen2Tokenizer.model_input_names" class="classattr">
                                <div class="attr variable">
            <span class="name">model_input_names</span>        =
<span class="default_value">[&#39;input_ids&#39;, &#39;attention_mask&#39;]</span>

        
    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.model_input_names"></a>
    
    

                            </div>
                            <div id="Qwen2Tokenizer.decoder" class="classattr">
                                <div class="attr variable">
            <span class="name">decoder</span>

        
    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.decoder"></a>
    
    

                            </div>
                            <div id="Qwen2Tokenizer.errors" class="classattr">
                                <div class="attr variable">
            <span class="name">errors</span>

        
    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.errors"></a>
    
    

                            </div>
                            <div id="Qwen2Tokenizer.byte_encoder" class="classattr">
                                <div class="attr variable">
            <span class="name">byte_encoder</span>

        
    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.byte_encoder"></a>
    
    

                            </div>
                            <div id="Qwen2Tokenizer.byte_decoder" class="classattr">
                                <div class="attr variable">
            <span class="name">byte_decoder</span>

        
    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.byte_decoder"></a>
    
    

                            </div>
                            <div id="Qwen2Tokenizer.bpe_ranks" class="classattr">
                                <div class="attr variable">
            <span class="name">bpe_ranks</span>

        
    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.bpe_ranks"></a>
    
    

                            </div>
                            <div id="Qwen2Tokenizer.cache" class="classattr">
                                <div class="attr variable">
            <span class="name">cache</span>

        
    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.cache"></a>
    
    

                            </div>
                            <div id="Qwen2Tokenizer.pat" class="classattr">
                                <div class="attr variable">
            <span class="name">pat</span>

        
    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.pat"></a>
    
    

                            </div>
                            <div id="Qwen2Tokenizer.vocab_size" class="classattr">
                                        <input id="Qwen2Tokenizer.vocab_size-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">vocab_size</span><span class="annotation">: int</span>

                <label class="view-source-button" for="Qwen2Tokenizer.vocab_size-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.vocab_size"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Qwen2Tokenizer.vocab_size-182"><a href="#Qwen2Tokenizer.vocab_size-182"><span class="linenos">182</span></a>    <span class="nd">@property</span>
</span><span id="Qwen2Tokenizer.vocab_size-183"><a href="#Qwen2Tokenizer.vocab_size-183"><span class="linenos">183</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">vocab_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.vocab_size-184"><a href="#Qwen2Tokenizer.vocab_size-184"><span class="linenos">184</span></a>        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p><code>int</code>: Size of the base vocabulary (without the added tokens).</p>
</div>


                            </div>
                            <div id="Qwen2Tokenizer.get_vocab" class="classattr">
                                        <input id="Qwen2Tokenizer.get_vocab-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_vocab</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Qwen2Tokenizer.get_vocab-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.get_vocab"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Qwen2Tokenizer.get_vocab-187"><a href="#Qwen2Tokenizer.get_vocab-187"><span class="linenos">187</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer.get_vocab-188"><a href="#Qwen2Tokenizer.get_vocab-188"><span class="linenos">188</span></a>        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">added_tokens_encoder</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Returns the vocabulary as a dictionary of token to index.</p>

<p><code>tokenizer.get_vocab()[token]</code> is equivalent to <code>tokenizer.convert_tokens_to_ids(token)</code> when <code>token</code> is in the
vocab.</p>

<p>Returns:
    <code>dict[str, int]</code>: The vocabulary.</p>
</div>


                            </div>
                            <div id="Qwen2Tokenizer.bpe" class="classattr">
                                        <input id="Qwen2Tokenizer.bpe-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">bpe</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">token</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Qwen2Tokenizer.bpe-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.bpe"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Qwen2Tokenizer.bpe-191"><a href="#Qwen2Tokenizer.bpe-191"><span class="linenos">191</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">bpe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer.bpe-192"><a href="#Qwen2Tokenizer.bpe-192"><span class="linenos">192</span></a>        <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.bpe-193"><a href="#Qwen2Tokenizer.bpe-193"><span class="linenos">193</span></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
</span><span id="Qwen2Tokenizer.bpe-194"><a href="#Qwen2Tokenizer.bpe-194"><span class="linenos">194</span></a>        <span class="n">word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.bpe-195"><a href="#Qwen2Tokenizer.bpe-195"><span class="linenos">195</span></a>        <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.bpe-196"><a href="#Qwen2Tokenizer.bpe-196"><span class="linenos">196</span></a>
</span><span id="Qwen2Tokenizer.bpe-197"><a href="#Qwen2Tokenizer.bpe-197"><span class="linenos">197</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">pairs</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.bpe-198"><a href="#Qwen2Tokenizer.bpe-198"><span class="linenos">198</span></a>            <span class="k">return</span> <span class="n">token</span>
</span><span id="Qwen2Tokenizer.bpe-199"><a href="#Qwen2Tokenizer.bpe-199"><span class="linenos">199</span></a>
</span><span id="Qwen2Tokenizer.bpe-200"><a href="#Qwen2Tokenizer.bpe-200"><span class="linenos">200</span></a>        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.bpe-201"><a href="#Qwen2Tokenizer.bpe-201"><span class="linenos">201</span></a>            <span class="n">bigram</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">pair</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">pair</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)))</span>
</span><span id="Qwen2Tokenizer.bpe-202"><a href="#Qwen2Tokenizer.bpe-202"><span class="linenos">202</span></a>            <span class="k">if</span> <span class="n">bigram</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.bpe-203"><a href="#Qwen2Tokenizer.bpe-203"><span class="linenos">203</span></a>                <span class="k">break</span>
</span><span id="Qwen2Tokenizer.bpe-204"><a href="#Qwen2Tokenizer.bpe-204"><span class="linenos">204</span></a>            <span class="n">first</span><span class="p">,</span> <span class="n">second</span> <span class="o">=</span> <span class="n">bigram</span>
</span><span id="Qwen2Tokenizer.bpe-205"><a href="#Qwen2Tokenizer.bpe-205"><span class="linenos">205</span></a>            <span class="n">new_word</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="Qwen2Tokenizer.bpe-206"><a href="#Qwen2Tokenizer.bpe-206"><span class="linenos">206</span></a>            <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="Qwen2Tokenizer.bpe-207"><a href="#Qwen2Tokenizer.bpe-207"><span class="linenos">207</span></a>            <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer.bpe-208"><a href="#Qwen2Tokenizer.bpe-208"><span class="linenos">208</span></a>                <span class="k">try</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.bpe-209"><a href="#Qwen2Tokenizer.bpe-209"><span class="linenos">209</span></a>                    <span class="n">j</span> <span class="o">=</span> <span class="n">word</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.bpe-210"><a href="#Qwen2Tokenizer.bpe-210"><span class="linenos">210</span></a>                <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.bpe-211"><a href="#Qwen2Tokenizer.bpe-211"><span class="linenos">211</span></a>                    <span class="n">new_word</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:])</span>
</span><span id="Qwen2Tokenizer.bpe-212"><a href="#Qwen2Tokenizer.bpe-212"><span class="linenos">212</span></a>                    <span class="k">break</span>
</span><span id="Qwen2Tokenizer.bpe-213"><a href="#Qwen2Tokenizer.bpe-213"><span class="linenos">213</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.bpe-214"><a href="#Qwen2Tokenizer.bpe-214"><span class="linenos">214</span></a>                    <span class="n">new_word</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">j</span><span class="p">])</span>
</span><span id="Qwen2Tokenizer.bpe-215"><a href="#Qwen2Tokenizer.bpe-215"><span class="linenos">215</span></a>                    <span class="n">i</span> <span class="o">=</span> <span class="n">j</span>
</span><span id="Qwen2Tokenizer.bpe-216"><a href="#Qwen2Tokenizer.bpe-216"><span class="linenos">216</span></a>
</span><span id="Qwen2Tokenizer.bpe-217"><a href="#Qwen2Tokenizer.bpe-217"><span class="linenos">217</span></a>                <span class="k">if</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">first</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">second</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.bpe-218"><a href="#Qwen2Tokenizer.bpe-218"><span class="linenos">218</span></a>                    <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">first</span> <span class="o">+</span> <span class="n">second</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.bpe-219"><a href="#Qwen2Tokenizer.bpe-219"><span class="linenos">219</span></a>                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">2</span>
</span><span id="Qwen2Tokenizer.bpe-220"><a href="#Qwen2Tokenizer.bpe-220"><span class="linenos">220</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.bpe-221"><a href="#Qwen2Tokenizer.bpe-221"><span class="linenos">221</span></a>                    <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="Qwen2Tokenizer.bpe-222"><a href="#Qwen2Tokenizer.bpe-222"><span class="linenos">222</span></a>                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="Qwen2Tokenizer.bpe-223"><a href="#Qwen2Tokenizer.bpe-223"><span class="linenos">223</span></a>            <span class="n">new_word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_word</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.bpe-224"><a href="#Qwen2Tokenizer.bpe-224"><span class="linenos">224</span></a>            <span class="n">word</span> <span class="o">=</span> <span class="n">new_word</span>
</span><span id="Qwen2Tokenizer.bpe-225"><a href="#Qwen2Tokenizer.bpe-225"><span class="linenos">225</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.bpe-226"><a href="#Qwen2Tokenizer.bpe-226"><span class="linenos">226</span></a>                <span class="k">break</span>
</span><span id="Qwen2Tokenizer.bpe-227"><a href="#Qwen2Tokenizer.bpe-227"><span class="linenos">227</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.bpe-228"><a href="#Qwen2Tokenizer.bpe-228"><span class="linenos">228</span></a>                <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.bpe-229"><a href="#Qwen2Tokenizer.bpe-229"><span class="linenos">229</span></a>        <span class="n">word</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.bpe-230"><a href="#Qwen2Tokenizer.bpe-230"><span class="linenos">230</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
</span><span id="Qwen2Tokenizer.bpe-231"><a href="#Qwen2Tokenizer.bpe-231"><span class="linenos">231</span></a>        <span class="k">return</span> <span class="n">word</span>
</span></pre></div>


    

                            </div>
                            <div id="Qwen2Tokenizer.convert_tokens_to_string" class="classattr">
                                        <input id="Qwen2Tokenizer.convert_tokens_to_string-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">convert_tokens_to_string</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">tokens</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Qwen2Tokenizer.convert_tokens_to_string-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.convert_tokens_to_string"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Qwen2Tokenizer.convert_tokens_to_string-253"><a href="#Qwen2Tokenizer.convert_tokens_to_string-253"><span class="linenos">253</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">convert_tokens_to_string</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer.convert_tokens_to_string-254"><a href="#Qwen2Tokenizer.convert_tokens_to_string-254"><span class="linenos">254</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts a sequence of tokens (string) in a single string.&quot;&quot;&quot;</span>
</span><span id="Qwen2Tokenizer.convert_tokens_to_string-255"><a href="#Qwen2Tokenizer.convert_tokens_to_string-255"><span class="linenos">255</span></a>        <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.convert_tokens_to_string-256"><a href="#Qwen2Tokenizer.convert_tokens_to_string-256"><span class="linenos">256</span></a>        <span class="n">text</span> <span class="o">=</span> <span class="nb">bytearray</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">text</span><span class="p">])</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">errors</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.convert_tokens_to_string-257"><a href="#Qwen2Tokenizer.convert_tokens_to_string-257"><span class="linenos">257</span></a>        <span class="k">return</span> <span class="n">text</span>
</span></pre></div>


            <div class="docstring"><p>Converts a sequence of tokens (string) in a single string.</p>
</div>


                            </div>
                            <div id="Qwen2Tokenizer.decode" class="classattr">
                                        <input id="Qwen2Tokenizer.decode-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">decode</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">token_ids</span>,</span><span class="param">	<span class="n">skip_special_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">clean_up_tokenization_spaces</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">spaces_between_special_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">) -> <span class="nb">str</span>:</span></span>

                <label class="view-source-button" for="Qwen2Tokenizer.decode-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.decode"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Qwen2Tokenizer.decode-259"><a href="#Qwen2Tokenizer.decode-259"><span class="linenos">259</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span>
</span><span id="Qwen2Tokenizer.decode-260"><a href="#Qwen2Tokenizer.decode-260"><span class="linenos">260</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.decode-261"><a href="#Qwen2Tokenizer.decode-261"><span class="linenos">261</span></a>        <span class="n">token_ids</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.decode-262"><a href="#Qwen2Tokenizer.decode-262"><span class="linenos">262</span></a>        <span class="n">skip_special_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.decode-263"><a href="#Qwen2Tokenizer.decode-263"><span class="linenos">263</span></a>        <span class="n">clean_up_tokenization_spaces</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.decode-264"><a href="#Qwen2Tokenizer.decode-264"><span class="linenos">264</span></a>        <span class="n">spaces_between_special_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.decode-265"><a href="#Qwen2Tokenizer.decode-265"><span class="linenos">265</span></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.decode-266"><a href="#Qwen2Tokenizer.decode-266"><span class="linenos">266</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.decode-267"><a href="#Qwen2Tokenizer.decode-267"><span class="linenos">267</span></a>        <span class="c1"># `spaces_between_special_tokens` defaults to True for _decode in slow tokenizers</span>
</span><span id="Qwen2Tokenizer.decode-268"><a href="#Qwen2Tokenizer.decode-268"><span class="linenos">268</span></a>        <span class="c1"># and cannot be configured elsewhere, but it should default to False for Qwen2Tokenizer</span>
</span><span id="Qwen2Tokenizer.decode-269"><a href="#Qwen2Tokenizer.decode-269"><span class="linenos">269</span></a>        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span>
</span><span id="Qwen2Tokenizer.decode-270"><a href="#Qwen2Tokenizer.decode-270"><span class="linenos">270</span></a>            <span class="n">token_ids</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.decode-271"><a href="#Qwen2Tokenizer.decode-271"><span class="linenos">271</span></a>            <span class="n">skip_special_tokens</span><span class="o">=</span><span class="n">skip_special_tokens</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.decode-272"><a href="#Qwen2Tokenizer.decode-272"><span class="linenos">272</span></a>            <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="n">clean_up_tokenization_spaces</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.decode-273"><a href="#Qwen2Tokenizer.decode-273"><span class="linenos">273</span></a>            <span class="n">spaces_between_special_tokens</span><span class="o">=</span><span class="n">spaces_between_special_tokens</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.decode-274"><a href="#Qwen2Tokenizer.decode-274"><span class="linenos">274</span></a>            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="Qwen2Tokenizer.decode-275"><a href="#Qwen2Tokenizer.decode-275"><span class="linenos">275</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Converts a sequence of ids in a string, using the tokenizer and vocabulary with options to remove special
tokens and clean up tokenization spaces.</p>

<p>Similar to doing <code>self.convert_tokens_to_string(self.convert_ids_to_tokens(token_ids))</code>.</p>

<p>Args:
    token_ids (<code>Union[int, list[int], np.ndarray, torch.Tensor, tf.Tensor]</code>):
        List of tokenized input ids. Can be obtained using the <code>__call__</code> method.
    skip_special_tokens (<code>bool</code>, *optional*, defaults to <code>False</code>):
        Whether or not to remove special tokens in the decoding.
    clean_up_tokenization_spaces (<code>bool</code>, <em>optional</em>):
        Whether or not to clean up the tokenization spaces. If <code>None</code>, will default to
        <code>self.clean_up_tokenization_spaces</code>.
    kwargs (additional keyword arguments, <em>optional</em>):
        Will be passed to the underlying model specific decode method.</p>

<p>Returns:
    <code>str</code>: The decoded sentence.</p>
</div>


                            </div>
                            <div id="Qwen2Tokenizer.save_vocabulary" class="classattr">
                                        <input id="Qwen2Tokenizer.save_vocabulary-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">save_vocabulary</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">save_directory</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">filename_prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="Qwen2Tokenizer.save_vocabulary-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.save_vocabulary"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Qwen2Tokenizer.save_vocabulary-278"><a href="#Qwen2Tokenizer.save_vocabulary-278"><span class="linenos">278</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">save_vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save_directory</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">filename_prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-279"><a href="#Qwen2Tokenizer.save_vocabulary-279"><span class="linenos">279</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">save_directory</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-280"><a href="#Qwen2Tokenizer.save_vocabulary-280"><span class="linenos">280</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Vocabulary path (</span><span class="si">{</span><span class="n">save_directory</span><span class="si">}</span><span class="s2">) should be a directory&quot;</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-281"><a href="#Qwen2Tokenizer.save_vocabulary-281"><span class="linenos">281</span></a>            <span class="k">return</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-282"><a href="#Qwen2Tokenizer.save_vocabulary-282"><span class="linenos">282</span></a>        <span class="n">vocab_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="p">(</span><span class="n">filename_prefix</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="k">if</span> <span class="n">filename_prefix</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="n">VOCAB_FILES_NAMES</span><span class="p">[</span><span class="s2">&quot;vocab_file&quot;</span><span class="p">])</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-283"><a href="#Qwen2Tokenizer.save_vocabulary-283"><span class="linenos">283</span></a>        <span class="n">merge_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="p">(</span><span class="n">filename_prefix</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span> <span class="k">if</span> <span class="n">filename_prefix</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="n">VOCAB_FILES_NAMES</span><span class="p">[</span><span class="s2">&quot;merges_file&quot;</span><span class="p">])</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-284"><a href="#Qwen2Tokenizer.save_vocabulary-284"><span class="linenos">284</span></a>
</span><span id="Qwen2Tokenizer.save_vocabulary-285"><a href="#Qwen2Tokenizer.save_vocabulary-285"><span class="linenos">285</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">vocab_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-286"><a href="#Qwen2Tokenizer.save_vocabulary-286"><span class="linenos">286</span></a>            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-287"><a href="#Qwen2Tokenizer.save_vocabulary-287"><span class="linenos">287</span></a>
</span><span id="Qwen2Tokenizer.save_vocabulary-288"><a href="#Qwen2Tokenizer.save_vocabulary-288"><span class="linenos">288</span></a>        <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-289"><a href="#Qwen2Tokenizer.save_vocabulary-289"><span class="linenos">289</span></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">merge_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-290"><a href="#Qwen2Tokenizer.save_vocabulary-290"><span class="linenos">290</span></a>            <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;#version: 0.2</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-291"><a href="#Qwen2Tokenizer.save_vocabulary-291"><span class="linenos">291</span></a>            <span class="k">for</span> <span class="n">bpe_tokens</span><span class="p">,</span> <span class="n">token_index</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">kv</span><span class="p">:</span> <span class="n">kv</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-292"><a href="#Qwen2Tokenizer.save_vocabulary-292"><span class="linenos">292</span></a>                <span class="k">if</span> <span class="n">index</span> <span class="o">!=</span> <span class="n">token_index</span><span class="p">:</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-293"><a href="#Qwen2Tokenizer.save_vocabulary-293"><span class="linenos">293</span></a>                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving vocabulary to </span><span class="si">{</span><span class="n">merge_file</span><span class="si">}</span><span class="s2">: BPE merge indices are not consecutive. Please check that the tokenizer is not corrupted!&quot;</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-294"><a href="#Qwen2Tokenizer.save_vocabulary-294"><span class="linenos">294</span></a>                    <span class="n">index</span> <span class="o">=</span> <span class="n">token_index</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-295"><a href="#Qwen2Tokenizer.save_vocabulary-295"><span class="linenos">295</span></a>                <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">bpe_tokens</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-296"><a href="#Qwen2Tokenizer.save_vocabulary-296"><span class="linenos">296</span></a>                <span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="Qwen2Tokenizer.save_vocabulary-297"><a href="#Qwen2Tokenizer.save_vocabulary-297"><span class="linenos">297</span></a>
</span><span id="Qwen2Tokenizer.save_vocabulary-298"><a href="#Qwen2Tokenizer.save_vocabulary-298"><span class="linenos">298</span></a>        <span class="k">return</span> <span class="n">vocab_file</span><span class="p">,</span> <span class="n">merge_file</span>
</span></pre></div>


            <div class="docstring"><p>Save only the vocabulary of the tokenizer (vocabulary + added tokens).</p>

<p>This method won't save the configuration and special token mappings of the tokenizer. Use
[<code>~PreTrainedTokenizerFast._save_pretrained</code>] to save the whole state of the tokenizer.</p>

<p>Args:
    save_directory (<code>str</code>):
        The directory in which to save the vocabulary.
    filename_prefix (<code>str</code>, <em>optional</em>):
        An optional prefix to add to the named of the saved files.</p>

<p>Returns:
    <code>tuple(str)</code>: Paths to the files saved.</p>
</div>


                            </div>
                            <div id="Qwen2Tokenizer.prepare_for_tokenization" class="classattr">
                                        <input id="Qwen2Tokenizer.prepare_for_tokenization-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">prepare_for_tokenization</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">text</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="Qwen2Tokenizer.prepare_for_tokenization-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Qwen2Tokenizer.prepare_for_tokenization"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Qwen2Tokenizer.prepare_for_tokenization-300"><a href="#Qwen2Tokenizer.prepare_for_tokenization-300"><span class="linenos">300</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_for_tokenization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="Qwen2Tokenizer.prepare_for_tokenization-301"><a href="#Qwen2Tokenizer.prepare_for_tokenization-301"><span class="linenos">301</span></a>        <span class="n">text</span> <span class="o">=</span> <span class="n">unicodedata</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="s2">&quot;NFC&quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
</span><span id="Qwen2Tokenizer.prepare_for_tokenization-302"><a href="#Qwen2Tokenizer.prepare_for_tokenization-302"><span class="linenos">302</span></a>        <span class="k">return</span> <span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Performs any necessary transformations before tokenization.</p>

<p>This method should pop the arguments from kwargs and return the remaining <code>kwargs</code> as well. We test the
<code>kwargs</code> at the end of the encoding process to be sure all the arguments have been used.</p>

<p>Args:
    text (<code>str</code>):
        The text to prepare.
    is_split_into_words (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):
        Whether or not the input is already pre-tokenized (e.g., split into words). If set to <code>True</code>, the
        tokenizer assumes the input is already split into words (for instance, by splitting it on whitespace)
        which it will tokenize. This is useful for NER or token classification.
    kwargs (<code>dict[str, Any]</code>, <em>optional</em>):
        Keyword arguments to use for the tokenization.</p>

<p>Returns:
    <code>tuple[str, dict[str, Any]]</code>: The prepared text and the unused kwargs.</p>
</div>


                            </div>
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>